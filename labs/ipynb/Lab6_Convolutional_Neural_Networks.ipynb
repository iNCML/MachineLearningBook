{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zl32IlrI2_2x"
   },
   "source": [
    "# **Lab 6: Convolutional Neural Networks**\n",
    "\n",
    "---\n",
    "NOTE: This is a lab project accompanying the following book [MLF] and it should be used together with the book.\n",
    "\n",
    "[MLF] *H. Jiang*, \"[Machine Learning Fundamentals: A Concise Introduction](http://wiki.eecs.yorku.ca/user/hj/research:mlfbook)\", Cambridge University Press, 2021.  ([bibtex](http://www.cse.yorku.ca/~hj/mlf-jiang.bib))\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sOfUN063FUN"
   },
   "source": [
    "The purpose of this lab is to explore more complex structures in neural networks beyond simple fully-connected networks. In particular, we focus on deep convolutional nerual networks (CNNs) for image classification as CNNs have become the dominant model for many computer vision tasks. Instead of implementing CNNs from scratch as what has been done in the previous Labs, we introduce some popular deep learning toolkits, such as *Tensorflow* and *Pytorch*, and use some examples to show how to use these toolkits to conveniently build various CNN structures and efficiently train/evaluate them with available training/test data. \n",
    "\n",
    "Prerequisites: N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFc-RfgojHyT"
   },
   "source": [
    "The most important feature in these popular deep learning toolkits (either *Tensorflow* or *Pytorch*) is to provide some flexible ways for us to specify various networks structures. These toolkits usually come up with many different syntaxes from various levels for this purpose. Some low-level syntaxes allow us to conveniently customize neural networks  in any way we prefer while other high-level syntaxes offer legible and flexible interfaces to configure  popular network structures in the literature. These toolkits allow us to directly use many popular building blocks introduced in [MLF] without reinventing the wheel, such as full connection, convolution, activation, softmax, attension, feedback and normalization layers. On the other hand, it also provides nice interfaces for us to implement any new modules. \n",
    "\n",
    "Another advantage to use these toolkits is that they come up with automatic differentiation (AD) module so that we do not need to explicitly implement error back-propagation. The learning process is almost totally automatic as long as we specify some key ingredients, such as a loss function, an optimization algorithm and relevant hyperparameters. Finally, these toolkits also provide a full support to allow us to flexibly switch hardware devices between CPUs, GPUs and even TPUs for the training/testing processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhRvb_hWnuWH"
   },
   "source": [
    "In this Lab, we only introduce how to use the high-level *Keras* style syntax to build deep convolutional neural networks for image classification tasks. When we use the *Keras* interface to build any complex neural networks, it usually consists of the following three steps:\n",
    "\n",
    "1.   **Define**: we use some highly legible syntax to clearly define the structure of neural networks in a layer by layer manner. In this step, we need to specify all network details in a static structure. \n",
    "\n",
    "2.   **Compile**: we compile the previously defined static network by associating it with some dynamic components, such as a loss function, an optimizer along with its hyperparameters, a hardware device to be used (CPUs or GPUs), an evaluation matric, etc. \n",
    "\n",
    "3.   **Fit**: we fit the compiled model to the available training data (as well as the corresponding target labels). It will run the specified optimizer and use the automatically derived gradients from AD to learn the model on the specified hardware device. \n",
    "\n",
    "In the following, we will use several examples to show how to do these three steps for convolutional neural networks using *Tensorflow* and *Pytorch*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZvsodzJlAlu"
   },
   "source": [
    "## **I. Using TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvIdky2Gi20Z"
   },
   "source": [
    "### **Example 6.1:**\n",
    "\n",
    "*Use Tensorflow to re-implement the fully-connected neural networks and compare it with various implementations in last Lab in terms of classification accuracy and running speed.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-mOvaJI1lt3"
   },
   "source": [
    "Here we can use an integer (between 0 and 9) as the target lable for each image. For this case, we need to specify the CE loss function as \"*sparse_categorical_crossentropy*\" in *Tensorflow*. If we use the one-hot vector as the target label for each image, we need to specify the CE loss function as \"*categorical_crossentropy*\" in *Tensorflow*. Note that *Tensorflow* uses GPUs by default as long as  GPUs are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUu2xzkt2kjP",
    "outputId": "700e56a4-ed0b-4330-8705-9ba76d6f9cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#link my Google drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJKOHJdO3mwM",
    "outputId": "4303a231-280a-423b-cec9-3105bc075156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_mnist\n",
      "  Downloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: python-mnist\n",
      "Successfully installed python-mnist-0.7\n"
     ]
    }
   ],
   "source": [
    "# install python_mnist\n",
    "\n",
    "!pip install python_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdG2Cre33vER",
    "outputId": "5adc0d9b-2f8f-460c-8e9d-1a7c061de138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,) (60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#load MINST images\n",
    "\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "\n",
    "mnist_loader = MNIST('/content/drive/My Drive/Colab Notebooks/datasets/MNIST')\n",
    "train_data, train_label = mnist_loader.load_training()\n",
    "test_data, test_label = mnist_loader.load_testing()\n",
    "X_train = np.array(train_data, dtype='float')/255.0 # norm to [0,1]\n",
    "y_train = np.array(train_label, dtype='short')\n",
    "X_test = np.array(test_data, dtype='float')/255.0 # norm to [0,1]\n",
    "y_test = np.array(test_label, dtype='short')\n",
    "\n",
    "#reshape each input vector (784) into a 28*28*1 image \n",
    "X_train = np.reshape(X_train, (-1,28,28,1)) \n",
    "X_test = np.reshape(X_test, (-1,28,28,1))\n",
    "\n",
    "# convert MNIST labels into 10-D one-hot vectors \n",
    "Y_train = np.zeros((y_train.size, y_train.max()+1))\n",
    "Y_train[np.arange(y_train.size),y_train] = 1\n",
    "Y_test = np.zeros((y_test.size, y_test.max()+1))\n",
    "Y_test[np.arange(y_test.size),y_test] = 1\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5fAyLUAeXTr",
    "outputId": "bdf36806-bd23-41ba-99b1-cef013e8f9b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.2488 - accuracy: 0.9258 - val_loss: 0.1248 - val_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0993 - accuracy: 0.9699 - val_loss: 0.1090 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0649 - accuracy: 0.9807 - val_loss: 0.0696 - val_accuracy: 0.9780\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.0682 - val_accuracy: 0.9788\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.9781\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.0640 - val_accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0590 - val_accuracy: 0.9813\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.0682 - val_accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0656 - val_accuracy: 0.9809\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.0584 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to implement a fully-connected neural networks (same structure as Lab5)\n",
    "#\n",
    "# use integers as target labels and specify CE loss as \"sparse_categorical_crossentropy\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# define the model structure using Keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dense(250, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# compile model by attaching with loss/optimizer/metric\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",      # CE loss for integer label \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-1),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# fit to training data to learn the model\n",
    "history = model.fit(X_train, y_train, epochs=10,          # y_train: integer labels\n",
    "                    validation_data=(X_test, y_test))     # y_test: integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCeB1Lsw3Rf6",
    "outputId": "b94d6bd7-2530-455a-9dd6-b0bbf499a597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2488 - accuracy: 0.9258 - val_loss: 0.1248 - val_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0993 - accuracy: 0.9699 - val_loss: 0.1090 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0649 - accuracy: 0.9807 - val_loss: 0.0696 - val_accuracy: 0.9780\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.0682 - val_accuracy: 0.9788\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.9781\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.0640 - val_accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0590 - val_accuracy: 0.9813\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.0682 - val_accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0656 - val_accuracy: 0.9809\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.0584 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to implement a fully-connected neural networks\n",
    "# use one-hot target labels and specify CE loss as \"categorical_crossentropy\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# define the model structure using Keras  (same network structure as Lab5)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dense(250, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# compile model by attaching with loss/optimizer/metric\n",
    "model.compile(loss=\"categorical_crossentropy\",      # CE loss for one-hot vector label \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-1),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# fit to training data to learn the model  \n",
    "history = model.fit(X_train, Y_train, epochs=10,        # Y_train: one-hot vector labels  \n",
    "                    validation_data=(X_test, Y_test))   # Y_test: one-hot vector labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "YNxIUHWAmEAP",
    "outputId": "81807ed2-a862-49d2-e7b9-e02293f3c008"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5aH/8c8zS2ayEQiBsFmBuoASMICoeNWgtdr+XLqIVK1W3KpVu9h7rbW29bbW29ba2+ValVr1YrXUpfZ6rVXLlUituAAqKAhSRAj7koQEMpnt+f1xZiYzWScwyYHh+3695jXnPM9znnnmEOY7Z5lzjLUWERERcY/H7QGIiIgc6hTGIiIiLlMYi4iIuExhLCIi4jKFsYiIiMsUxiIiIi7rMYyNMQ8aY7YZY97tot4YY35ljFljjFlmjJmc+2GKiIjkr2y2jB8Gzu6m/lPAkYnHNcC9+z8sERGRQ0ePYWytXQjs6qbJ+cBc63gNGGiMGZ6rAYqIiOS7XBwzHglsSJuvS5SJiIhIFnz9+WLGmGtwdmVTWFg45bDDDstZ3/F4HI9H56P1B63r/nFormeLAci4TK9tV5dZlmSwWdR1rLfxOB5jOpRnjiNRZtv3vb/l6a/XcfwmWd9peXK2s0sa6zLHuWCNl+aSMTnrb/Xq1TustUM6q8tFGG8E0lN1VKKsA2vtHGAOwNSpU+3ixYtz8PKO2tpaampqctafdE3ruo/E4xALJx4RXn3lZaafOA3iUYhFned4FOIRiMfa5mPt5jutj6aVtZvvVX1Py0bBxpx5G3ce8VhaWcx5n+nzyXYHDQMeH3i8zrPxJqbT5z1p0762etO+XRfznS7na5s2Huc1MM60STy3n0+VmSzaeNra9dimu347H8+yZcuZOGlSt216HnNXy3XRV6fLkeV7S18fOfrLMeajrupyEcbPADcYY+YBJwCN1trNOehXJDesdUIjLeiItXZSlpiOhjsvTy2XXt6b5Xp4PRvLGPZ0gEV9vG5MIjQ8/syA8frbplP1afNev/PwF6bVezJDJRlKxtOuLBkm6cGS3r59W6/zgdi+LKOf9st18Zqd1L2+eDEnnDi9Y+B1CMpkXe4+nA8luzb64Ygat4dxwOoxjI0xfwBqgApjTB3wfcAPYK29D3gO+DSwBtgLzO6rwcpBLh6DaAiirRBpSUyH2pW1QrSl8/loCCKhzOW6nG+3XF/wFiQe/i6mEw9fAAKlbfW+QM/LeP2s+ueHHD3umLRAbPfwdlGeTb3X3xZMh7iWoi1QPtbtYcgBxFoLMWcvjiko6JfX7DGMrbUX9VBvgetzNiJxl7XQuhtCjdDSAKGGxHOjMx1q5ONrP4A9/9tJiHYRkMk28cj+jc0XdILMV+g8+xPPvqDzCA4Ef7Bt3hd05r2BRAB2EZ6pup4DMmO6j7eQNrfUcvTkml4vZ62FaBQbj6eebSQK8Tg2GoJYu7poss7ZdZz+bGPJumzaJHZBY53+Lc7fk42Dtdi4Tcw7ZdZaSCuziXapsvb9pPruZT+pMhK7yG1GP2Xbt1P3P/+DSe6W9HgwnrTdlB6DSe4S9nic+fZt0+s6tE305XF2eZrk3oKMOk9iz6in87bpdcldp4n14by/5Hsl9f4yytPWaVs5beuxfXl3fSfXX7Z9J+pK129gy8K/O/8WMefQhI3FIRbrWBaPOf8+sRg2HnNeI6Ms7vzNJeval8WS02nP6a8Ti6UCN/WcaEusbQ+Vp6yMo19/bV/++/Zav57AJf0kFk0Lz4bOQzVt2u6tJ767gVhjE7GmZmKthljYQyxsiLV6iIc9iXnnYa2HDz0enJPx246x2NS8SdQFsBQ6ZalTTkza6ScmdZ6JtYmytPNObOqDhdR/bpv+H9zGIb4Hy562ssSHrU12kPowIO3YknFGkPgw7VDW7pFRnmoPho5tO5QnP2S7aps6Ptex7/Km3ay9++fYWMz5sEh+MEVjGWFKNJqoc6Y7P6HnIND+38NkrkcDndd3W0ZGcKb+LdKW8e3ZQ2tDg/OhnR7a8Xha4HRfRzzu/M11UZeXevn/JxiPs7ugwFnG63W+XHg8zrPXm/gi4+28zOtx/h29XowxGJ8P4018OUmvSy9L78uTXpb2Ot7EYY701/G0lXmChf22OhXGB6pIKDNI07dUu9hqtXvqie1uIta8p0OAxloT4Rr2EIv4iEX8xMIe4q2GWGviQ4Zg4pHJU1SId8AAPAMH4i0bSMPu3ZQPHpz6sHP+w2X+x8z4EEz+p0xuQaQ+ME0nYUTah6on8zV66i9ZltFn4jmbLYGMb/y0C/POtwQ63Wpo30/Wfae1tZaYz0dBZWXiQybxQeH1pZ6N1wNen/Ph4fN2XudNfvB5U2061Hm9qWfjdY6TGl+7svbPyTaJ52Rd29Zc8t/Ek/hulkWIuqS2tpaqPj4hMSOck393yaBOn7fJvQHp8217F1JBD4BJ/Km3C0DSvuilr2fSytq1z+gn0b7LcN3Hfyud+Nk9hbEbmrfDhy9D3WLYu7NjqDY3EAtFEgHatoWaHq7xaIETqBGvsyUbssRbLVCSeHTkKS3BWzYQb/lAvGVlFJSV4R1YhnegM+8pK8NbVua0GZiYHjAA4/dn9PNhbS3H6T9Vn/tnbS3VWs95ISMYAfe+esiBSmG8D6y12HAYGwoRb23FJh7xUCs23NqxfM9u7OZV2K2riG/9J3b3NuIxg40XEIsHnC3VsMcJ1JYC4uHBXb+4x4N3wAAnPCucIC1IBmgyTJNBmnh4kqHq9fbfShIRkazlRRjHQyE8DQ2E16/PCMV4KIRtDWNbE+GYKk8GZYh4qxOq6eXx1sRyoRDxcGK51taMgN0v3jI8gQCmsMjZKh1Shr+sjGBamGZspaYFrKekJHGCiIiI5Iu8COPGZ55hyPe+zz97uZwpKMAEAphgAE9BABMMYgIFeAJBTCCAt7S0rT4QwAQy6z3BgFMfCOBp3YWpX43Z+R6e7csx8T3OL0eGH40ZcxLmiFPwjP0XTOlAbaGKiEiGvAjjoqlT2X3JxRxdVYUnGMQUBJzQTEy3hWYQT6DACd2Cgv3bwmzaAmtfhrW1zqNpk1M+aDRM+gyMrYHRp0JxN7ucRUREyJMwDowdS8sppzCwL092aW2Cdf9oC9/tK53ywnIYe5oTvmNOg/IxfTcGERHJS3kRxn0iFnHOdk6G78bFznV3fUE4fDocd5ETwJVVuoqRiIjsF4VxkrWwbUXbrueP/gHhZue3riOq4eSvOeE7appzVScREZEcObTDuLGubct37cuwZ5tTPvgImPSFxHHff4HCQe6NUURE8t6hFcYtDbDu720BvHONU148xAnesTXOcd+BubvPsoiISE/yO4yjrbDh9bbw3fSWc1k5f7GzxTv1CieAhx6TulyciIhIf8uvMI7HYevytvD9aJFzGz3jhVHHw6k3O+E7cgr4+ue2WCIiIj3JjzD+aBHHvPdTeH02tOxyyoaMhymXO+F7+HQIDnBxgCIiIl3LjzDes52yxvdh/NmJ476nwoDhbo9KREQkK/kRxuP+H4tOKqVmxgy3RyIiItJr+XG1Co9XJ2CJiMhBKz/CWERE5CCmMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERERlymMRUREXKYwFhERcZnCWERExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERERlymMRUREXKYwFhERcZnCWERExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXZRXGxpizjTGrjDFrjDG3dFL/MWPMAmPMW8aYZcaYT+d+qCIiIvmpxzA2xniBe4BPAccAFxljjmnX7DbgcWttNfAF4De5HqiIiEi+ymbLeBqwxlq71lobBuYB57drY4EBiekyYFPuhigiIpLfjLW2+wbGXACcba29KjF/KXCCtfaGtDbDgReBQUAx8Alr7ZJO+roGuAagsrJyyrx583L1PmhubqakpCRn/UnXtK77h9Zz/9B67h9azzBjxowl1tqpndX5cvQaFwEPW2vvNsacBDxijJlgrY2nN7LWzgHmAEydOtXW1NTk6OWhtraWXPYnXdO67h9az/1D67l/aD13L5vd1BuBw9LmRyXK0l0JPA5grV0EBIGKXAxQREQk32UTxm8CRxpjxhhjCnBO0HqmXZv1wBkAxpjxOGG8PZcDFRERyVc9hrG1NgrcALwArMQ5a/o9Y8wPjDHnJZp9E7jaGPMO8AfgctvTwWgREREBsjxmbK19DniuXdn30qZXACfndmgiIiKHBl2BS0RExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERERlymMRUREXKYwFhERcZnCWERExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERERlymMRUREXKYwFhERcZnCWERExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERERlymMRUREXKYwFhERcZnCWERExGUKYxEREZcpjEVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERc5nN7ACIisn8ikQh1dXWEQiG3h9KlsrIyVq5c6fYw+kUwGGTUqFH4/f6sl1EYi4gc5Orq6igtLWX06NEYY9weTqeampooLS11exh9zlrLzp07qaurY8yYMVkvl9VuamPM2caYVcaYNcaYW7poc6ExZoUx5j1jzGNZj0BERPZLKBRi8ODBB2wQH0qMMQwePLjXeyl63DI2xniBe4AzgTrgTWPMM9baFWltjgS+DZxsra03xgzt1ShERGS/KIgPHPvyb5HNlvE0YI21dq21NgzMA85v1+Zq4B5rbT2AtXZbr0ciIiJyiMomjEcCG9Lm6xJl6Y4CjjLG/MMY85ox5uxcDVBERA58JSUlbg/hoJarE7h8wJFADTAKWGiMqbLWNqQ3MsZcA1wDUFlZSW1tbY5eHpqbm3Pan3RN67p/aD33j3xYz2VlZTQ1Nbk9jG7HEIvFDogx9pdQKNSrv6tswngjcFja/KhEWbo64HVrbQT40BizGiec30xvZK2dA8wBmDp1qq2pqcl6oD2pra0ll/1J17Su+4fWc//Ih/W8cuXKA+JM5dLSUqy13Hzzzfz1r3/FGMNtt93GrFmz+OCDD7jyyivZvXs30WiUe++9l+nTp3PllVeyePFijDFcccUVfOMb33D7beREMBikuro66/bZhPGbwJHGmDE4IfwF4OJ2bf4MXAQ8ZIypwNltvTbrUYiISE78+/++x4pNu3Pa5zEjBvD9c4/Nqu2f/vQn3n77bd555x127NjB8ccfz6mnnsoTTzzBWWedxXe+8x1isRh79+7l7bffZuPGjbz77rsANDQ09NB7/urxmLG1NgrcALwArAQet9a+Z4z5gTHmvESzF4CdxpgVwALg36y1O/tq0CIicmB65ZVXuOiii/B6vVRWVnLaaafx5ptvMnnyZB566CFuv/12li9fTmlpKWPHjmXt2rXceOONPP/88wwYMMDt4bsmq2PG1trngOfalX0vbdoCNyUeIiLikmy3YPvbySefzMKFC/nLX/7C5Zdfzk033cRll13GO++8wwsvvMB9993H448/zoMPPuj2UF2ha1OLiEjOnHLKKfzxj38kFouxfft2Fi5cyLRp01i/fj2VlZVcffXVXHXVVSxdupQdO3YQj8f5/Oc/zx133MHSpUvdHr5rdDlMERHJmc9+9rMsWrSISZMmYYzhpz/9KcOGDePPf/4zs2bNwu/3U1JSwty5c9m4cSOzZ88mHo8D8B//8R8uj949CmMREdlvzc3NgHP1qbvuuou77roro/6SSy7h2muv7bDcobw1nE67qUVERFymMBYREXGZwlhERMRlCmMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERE5aESjUbeH0CcUxiIikhOf+cxnmDJlCsceeyxz5swB4Pnnn2fy5MlMnz6dM844A3AuEDJ79myqqqqYOHEiTz31FAAlJSWpvp588kkuv/xyAC6//HKuvfZaTjjhBG6++WbeeOMNTjrpJKqrq5k+fTqrVq0CnHsm/+u//isTJkxg4sSJ/PrXv+all17iM5/5TKrfv/3tb3z2s5/tj9XRK7oCl4hIPvnrLbBleW77HFYFn/pxj80efPBBysvLaWlp4fjjj+f888/n6quvZuHChVRUVBCJRAD44Q9/SFlZGcuXO+Osr6/vse+6ujpeffVVvF4vu3fv5u9//zs+n4/58+dz66238tRTTzFnzhzWrVvH22+/jc/nY9euXQwaNIivfOUrbN++nSFDhvDQQw9xxRVX7N/66AMKYxERyYlf/epXPP300wBs2LCBOXPmcOqppzJmzBiampooLy8HYP78+cybNy+13KBBg3rse+bMmXi9XgAaGxv50pe+xAcffIAxJhXy8+fP59prr8Xnc6It+XqXXnopv//975k9ezaLFi1i7ty5uXvTOaIwFhHJJ1lswfaF2tpa5s+fz6JFiygqKqKmpobjjjuO999/P+s+jDGp6VAolFFXXFycmv7ud7/LjBkzePrpp1m3bh01NTXd9jt79mzOPfdcgsEgM2fOTIX1gUTHjEVEZL81NjYyaNAgioqKeP/993nttdcIhUIsXLiQDz/8EIBdu3YBcOaZZ3LPPfeklk3upq6srGTlypXE4/HUFnZXrzVy5EgAHn744VT5mWeeyf333586ySv5eiNGjGDEiBHccccdzJ49O3dvOocUxiIist/OPvtsotEo48eP55ZbbuHEE09kyJAhzJkzh8997nNMnz6dWbNmAXDbbbdRX1/PhAkTmDRpEgsWLADgxz/+Meeccw7Tp09n+PDhXb7WzTffzLe//W2qq6szzq6+6qqr+NjHPsbEiROZNGkSjz32WKrukksu4bDDDmP8+PF9tAb2j7HWuvLCU6dOtYsXL85Zf7W1tT3uqpDc0LruH1rP/SMf1vPKlSsP2JBJampqorS01LXXv+GGG6iurubKK6/sl9fr7N/EGLPEWju1s/YH3o5zERGRHJoyZQrFxcXcfffdbg+lSwpjERHJa0uWLHF7CD3SMWMRERGXKYxFRERcpjAWERFxmcJYRETEZQpjERERlymMRUSk36Xfoam9devWMWHChH4cjfsUxiIiIi7T74xFRPLIT974Ce/vyv7mDNkYVz6Ob037VrdtbrnlFg477DCuv/56AG6//XZ8Ph8LFiygvr6e1tZW7rzzTs4///xevXYoFOK6665j8eLF+Hw+fv7znzNjxgzee+89Zs+eTTgcJh6P89RTTzFixAguvPBC6urqiMVifPe7301dgvNApzAWEZH9NmvWLL7+9a+nwvjxxx/nhRde4Ktf/SoDBgxg3bp1fOITn+C8887LuDtTT+655x6MMSxfvpz333+fT37yk6xevZr77ruPr33ta1xyySWEw2FisRjPPfccI0aM4C9/+Qvg3FDiYKEwFhHJIz1twfaV6upqtm3bxqZNm9i+fTuDBg1i2LBhfOMb32DhwoUAbNy4ka1btzJs2LCs+33llVe48cYbARg3bhyHH344q1ev5qSTTuJHP/oRdXV1fO5zn+PII4+kqqqKb37zm3zrW9/inHPO4ZRTTumT99oXdMxYRERyYubMmTz55JP88Y9/ZNasWTz66KNs376dJUuW8I9//IPKysoO9yneVxdffDHPPPMMhYWFfPrTn+all17iqKOOYunSpVRVVXHbbbfxgx/8ICev1R+0ZSwiIjkxa9Ysrr76anbs2MHLL7/M448/ztChQ/H7/bz44ot89NFHve7zlFNO4dFHH+X0009n9erVrF+/nqOPPpq1a9cyduxYvvrVr7J+/XqWLVvGuHHjKC8v54tf/CIDBw7kgQce6IN32TcUxiIikhPHHnssTU1NjBw5kuHDh3PJJZdw7rnnUlVVxaRJkxg3blyv+/zKV77CddddR1VVFT6fj4cffphAIMDjjz/OI488gt/vZ9iwYdx66628+eab/Nu//Rsejwe/38+9997bB++ybyiMRUQkZ5YvX56arqioYNGiRUDH+xk3Nzd32cfo0aN59913AQgGgzz00EMd2txyyy3ccsstGWVnnXUWZ5111n6N3y06ZiwiIuIybRmLiIgrli9fzqWXXppRFggEeP31110akXsUxiIi4oqqqirefvttt4dxQNBuahEREZcpjEVERFymMBYREXGZwlhERMRlCmMREel33d3P+FCkMBYRkUNWNBp1ewiAftokIpJXttx5J60rc3s/48D4cQy79dZu2+TyfsbNzc2cf/751NfXE4lEuOOOO1LLzZ07l5/97GcYY5g4cSKPPPIIW7du5dprr2Xt2rUA3HvvvYwYMYJzzjkndSWvn/3sZzQ3N3P77bdTU1PDcccdxyuvvMJFF13EUUcdxR133EE4HGbw4ME8+uijVFZW0tzczI033sjixYsxxvD973+fxsZGli1bxi9+8QsAfvvb37JixQr+8z//c5/XLyiMRUQkB3J5P+NgMMjTTz/NgAED2LFjByeeeCLnnXceK1as4I477uDVV1+loqKCXbt2AfDVr36V0047jaeffppYLEZzczP19fXdvkY4HGbx4sUA1NfX89prr2GM4YEHHuCnP/0pd999Nz/84Q8pKytLXeKzvr4ev9/Pj370I+666y78fj8PPfQQ999///6uvuzC2BhzNvBLwAs8YK39cRftPg88CRxvrV2836MTEZFe6WkLtq/k8n7G1lpuvfVWFi5ciMfjSS330ksvMXPmTCoqKgAoLy8H4KWXXmLu3LkAeL1eysrKegzjWbNmpabr6uqYNWsWmzdvJhwOM2bMGADmz5/PvHnzUu0GDRoEwOmnn86zzz7L+PHjiUQiVFVV9WZVdarHMDbGeIF7gDOBOuBNY8wz1toV7dqVAl8DDr3rmImISOp+xlu2bOlwP+NQKERVVVVW9zNOX87v9zN69Ohe3wfZ5/MRj8dT8+2XLy4uTk3feOON3HTTTZx33nnU1tZy++23d9v3VVddxZ133sm4ceOYPXt2r8bVlWxO4JoGrLHWrrXWhoF5QGc7/X8I/ATIzZ2jRUTkoDJr1izmzZvHk08+ycyZM2lsbEzdz3jhwoVZ3884fbkFCxakljv99NN54okn2LlzJ0BqN/UZZ5yRul1iLBajsbGRyspKtm3bxs6dO2ltbeXZZ5/t9vVGjhwJwH//93+nys8880zuueee1Hxya/uEE05gw4YNPPbYY1x00UXZrp5uZRPGI4ENafN1ibIUY8xk4DBr7V9yMioRETnodHY/48WLF1NVVcUf/vCHrO9nnL7c3LlzU8sde+yxfOc73+G0005j0qRJ3HTTTQD88pe/ZMGCBVRVVTFlyhRWrFiB3+/ne9/7HtOmTePMM8/s9rVvv/12Zs6cyZQpU1K7wAFuu+026uvrmTBhApMmTWLBggWpugsvvJCTTz45tet6fxlrbfcNjLkAONtae1Vi/lLgBGvtDYl5D/AScLm1dp0xphb4186OGRtjrgGuAaisrJySvi9+fzU3N+t3a/1E67p/aD33j3xYz2VlZRxxxBFuD6NbsVgMr9fr9jByZubMmVx//fXU1NR0Wr9mzRoaGxszymbMmLHEWju1s/bZnMC1ETgsbX5UoiypFJgA1CbOkBsGPGOMOa99IFtr5wBzAKZOnWq7ehP7ora2tsuVIrmldd0/tJ77Rz6s55UrV1JaWur2MLrV1NR0wI8xGw0NDUybNo1JkyZx7rnndtkuGAxSXV2ddb/ZhPGbwJHGmDE4IfwF4OJkpbW2EUht13e3ZSwiIpJ0MN7PeODAgaxevTrn/fYYxtbaqDHmBuAFnJ82PWitfc8Y8wNgsbX2mZyPSkREesVa2+Pvdw80+Xo/454O/3Ymq98ZW2ufA55rV/a9LtrW9HoUIiKyz4LBIDt37mTw4MEHXSDnG2stO3fuJBgM9mo5XYFLROQgN2rUKOrq6ti+fbvbQ+lSKBTqdUAdrILBIKNGjerVMgpjEZGDnN/vT1016kBVW1vbqxOaDjW6a5OIiIjLFMYiIiIuUxiLiIi4TGEsIiLiMoWxiIiIyxTGIiIiLlMYi4iIuExhLCIi4jKFsYiIiMsUxiIiIi5TGIuIiLhMYSwiIuIyhbGIiIjLFMYiIiIuUxiLiIi4TGEsIiLiMoWxiIiIyxTGIiIiLlMYi4iIuExhLCIi4jKFsYiIiMsUxiIiIi5TGIuIiLhMYSwiIuIyhbGIiIjLFMYiIiIuUxiLiIi4TGEsIiLiMoWxiIiIyxTGIiIiLlMYi4iIuExhLCIi4jKFsYiIiMvyIozX79zL75a30hKOuT0UERGRXsuLMH5rQz2vbIxyyQOvUb8n7PZwREREeiUvwvj840Zy/XEB3t20mwvue5W6+r1uD0lERCRreRHGAFOH+Xjkimlsa2rl8/e+yvtbdrs9JBERkazkTRgDnDB2ME9cexIAM+9bxOtrd7o8IhERkZ7lVRgDjBs2gD995WSGlga49ME3eP7dzW4PSUREpFt5F8YAIwcW8uS105kwYgDXPbqUR177yO0hiYiIdCkvwxhgUHEBj151IqcfPZTv/vldfv7iKqy1bg9LRESkg7wNY4DCAi/3XzqFC6eO4lcvreHWp5cTjcXdHpaIiEgGn9sD6Gs+r4effH4ilQOC/PqlNWxvCvNfF1cT9HvdHpqIiAiQ51vGScYYvvnJo/nB+cfyf+9v5ZIHXqdhry4OIiIiB4aswtgYc7YxZpUxZo0x5pZO6m8yxqwwxiwzxvyfMebw3A91/1120mjuuXgyy+saueC+RWxqaHF7SCIiIj2HsTHGC9wDfAo4BrjIGHNMu2ZvAVOttROBJ4Gf5nqgufLpquH89xXT2NoY4nO/eZXVW5vcHpKIiBzistkyngassdautdaGgXnA+ekNrLULrLXJa1C+BozK7TBz66SPDw2FglgAABWNSURBVOaPXz6JuLVccO+rvLlul9tDEhGRQ5jp6ec+xpgLgLOttVcl5i8FTrDW3tBF+/8Ctlhr7+ik7hrgGoDKysop8+bN28/ht2lubqakpKRXy2zfG+fuJSF2tliunRRgSmXen8+WE/uyrqX3tJ77h9Zz/9B6hhkzZiyx1k7trC6n6WOM+SIwFTits3pr7RxgDsDUqVNtTU1Nzl67traWfenvjNPCXPHwm9zzdgN3fOYoLj7hYzkbU77a13UtvaP13D+0nvuH1nP3stlNvRE4LG1+VKIsgzHmE8B3gPOsta25GV7fKy8u4LGrT+C0o4Zw69PL+cX81bo4iIiI9KtswvhN4EhjzBhjTAHwBeCZ9AbGmGrgfpwg3pb7YfatogIfcy6bygVTRvGL+R/wnT+/SyyuQBYRkf7R425qa23UGHMD8ALgBR601r5njPkBsNha+wxwF1ACPGGMAVhvrT2vD8edc36vh7sumMjQ0gC/qf0nO5pa+dVFujiIiIj0vayOGVtrnwOea1f2vbTpT+R4XK4wxnDz2eMYWhrg359dwaW/e50HLjuesiK/20MTEZE8dkhcgau3Lj95DL++qJp3NjQy8/5X2dyoi4OIiEjfURh34ZyJI3h49vFsagjx+d+8yge6OIiIiPQRhXE3ph9RwR+/fCKRuOWC+xax5CNdHERERHJPYdyDY0eU8afrplNeXMDFv32dv63Y6vaQREQkzyiMs3BYeRFPXnsS44aV8uVHFjPvjfVuD0lERPKIwjhLg0sCPHb1iZxy5BBu+dNyfv1/H+jiICIikhMK414oDvh44EtT+dzkkdz9t9V89390cRAREdl/ujNCL/m9Hu6eOYkhpQHuf3ktO5rC/OILx+niICIiss+0ZbwPjDF8+1Pj+e45x/D8e1u47ME3aGyJuD0sERE5SCmM98OV/zKGX11UzVvr65l1/yK2NIbcHpKIiByEFMb76bxJI3jo8mls2LWXz9/7Kmu2Nbs9JBEROcgojHPgX46s4I9fPonWaIwL7nuVpevr3R6SiIgcRBTGOTJhZBlPXTedskI/F//2NV56XxcHERGR7CiMc+jwwcU8dd10jhxaytVzl/D4mxvcHpKIiBwE8uKnTS+se4E76+5k1HOjGFI4hIrCitQjfb68sBy/p29vh1hREmDeNSdy7e+XcPNTy9jWFOL6GUeQuM+ziIhIB3kRxuXBcj4e/Dhen5ePdn/Ekq1LaGht6LTtoMAgKooqqAhWMKRoCIMLB3cI8IrCCkr8JfscoMUBH7/70vHc/OQ7/OzF1WxrauX75x6L16NAFhGRjvIijI8fdjx7KvZQU1OTKgvHwuwK7WL73u3saNnB9pbt7GzZmTG9bss6drTsIBLv+BvhoDfYZVCnh3h5sByfp+NqLPB5+PmFxzGkNMBv//4hO5pb+fmFujiIiIh0lBdh3JkCbwHDiocxrHhYt+2stewO706F9I6WHexs2emEeGgHO/bu4MPGD3ljyxvsDu/usLzBMCg4qGNgJ0L8rCkV+IMD+M3/rWPnQ6389rLjGRDs213lIiJycMnbMM6WMYayQBllgTI+PvDj3bYNx8JOUCdCO/lIze/dwdrGtexo2UE0Hs1YtvRoeC/u59THyhg3ZCQjSodSWVTJhIoJTKmc0uOXBhERyV+HfBj3RoG3gOElwxleMrzbdtZaGlsbM4O6ZQdvb9rA/NUf8P7mPTSGP+CVja/w+5W/B2BE8QgmV06memg1UyqnMLZsrE76EhE5RCiM+4AxhoHBgQwMDuSIQUe0VUyAZcc0MPuhN9myxfLby6opKt3O0q1LWbptKa9uepVn1z4LwMDAwFQwVw+tZvzg8X1+JriIiLhDYdzPJo4ayFPXTeeyB9/g4gcWU33YQCYdNoXTR53O16vKiPu289a2t1iydQlLty1lwYYFABT6CplYMZHJlZOZXDmZiRUTKfIXufxuREQkFxTGLhhd4Vwc5De1a3hrfQMP/2Md4VgcgPLiAqpGjmTSqGP45vgbGTk4ykd7301tPd/3zn1YLF7jZXz5+FQ4Tx46mUHBQS6/MxER2RcKY5cMKQ3w/XOPBSAcjbNqSxPv1DWwrK6BZXWN/NeC7cSt03ZEWZCJoz7JjMNm8uUjfcQD63i/fhlLti5h3vvzmLtiLgBjy8amdm1PrpzMiOIROu4sInIQUBgfAAp8HqpGlVE1qgw4HIC94SjvbdrNOxsaeKeukWV1DTz/3pbUMmMrJjJx1ClcO6aY0gFbaIivYtmOt3hx3Ys89cFTAFQWVaa2midXTuaIgUfgMboCqojIgUZhfIAqKvBx/Ohyjh9dnipr2BtmWSKY36lrZNHanfz57U0A+DwjOapyHKeOuobhoxqJBf7JxpYVLNmyhL9++FcABhQMoHpodSqgjx18LH6vTgoTEXGbwvggMrCogFOPGsKpRw1JlW3dHUpsPTu7t//67jYaWyJAJQHfcI4Z8Rmqh4cpLltPEx/wQeMyXq57GYCAN0BVRRWTKyczZegUJg2dRLG/2KV3JyJy6FIYH+QqBwT55LHD+OSxzkVDrLV8tHNvKpyX1TXwl6VhWiJDgCGUBk/lmFGGiorN2MBatrau5HfLf8ccOweP8XD0oKNTx5yrh1ZTUVjh7hsUETkEKIzzjDGG0RXFjK4o5vzjRgIQjcX5YFtzavf2sroGlrwxhGi8ApjG4FLLESN3UFS6nuboBzyx+onUxUhGDxid2rU9ZegURpWOcvHdiYjkJ4XxIcDn9TB++ADGDx/ArOOdslAkxsrNu1lW15jYii5lyaohWDsFiDK8cidDKjZBdC0vrJvP02ueBpw7ZHmiHu5++m6MMXjwOM/Gg9d4U2Ue0/ZI1qeXp8rSyjPKEuXGGLzG21bfRZnH00U/aWUGk9FHaj5xUpvHeDD0MN9ZP4myZPus5tPKunqt9a3rWbVrFX6PH5/H1/FhfPg9frwer07MyyPhWJjmSDN7wntojjQ7j7DzvCfilEXjUXweH17jdR4eLz7jw+tx5pN/I13VpZ6Tdb3oQ39rfUNhfIgK+r1Uf2wQ1R9r+21yUyjC8o2NbSeJbRjNxoZqII43sJ1hQzcR9G4mFmmiuGgAAZ8h4DcEfAZjLNZa4sSJ27ZHsiwWjxEl2lZm48RsDIvNaB+38c7Luum7q7K88L/ZNfMYDz7TMbBTQd5JXaqN6TrsM/pIeyQ/rDPqjI8CbwEF3gIC3kDbtCfQabnP+PLqp3eRWISmSFO3IdrZfHJ6T2QPTeGmTu8idyAxGLwer/NFMBHUXtNzkO9p2sO8+fMo8hVR6CvM7uF3npPLFPmK8vakU4WxpJQG/Uz/eAXTP952nHhHcyvLU1vPjbz7USPbmlpZ027ZskI/w8uCjBhYmHoeNiDI8IFBRpQVMqws2K+3j7TWZoR6cjpZnl4PZLRJzae1jZOYT1uufT9dzqcvn+yvXfvUa1tSXybeWfYO444dRzQeTT0i8UjbvI1m1HWYb1eXsWw8Smu0lT3xPRnLddd/zMZy+m/kMR4KPJ2EtzeQUe73+juUddU2q/K0ab/HT9RGqQ/Vp4IyPRjbB2X6fEawhpsJx8M9vmef8VFSUEKxv5gSv/M8tGgoY/xjnPkCp7zEX5LRrv28z+MjZmPOl1wbJRaPEbOx1L9Tsjwa77ouvTx9vtP6bpZNlsdsjEg8kjGfXr+XvTSEGtgc3UxLtCX1aI219urvxmd8HcK6N+He3ZeBgDfg2hdEhbF0q6IkwIxxQ5kxbmiq7G8vLeDoSSewqbGFzY0tbGoIsbmxhc0NITY3hnhrfT31ezt+ux9cXMDwgUGGlxUyoizI8LTgHl4WpHJAEL83N7vA2u8GPhjF18SpObzG7WGkWGvbAruL4I/EI7TGWgnHwoRjYWc6njadKA/Hwx3bdVLeFG7qso/WWCsWm5s3t7776mxCtNRf6tSnh2hBSap9ib8kpx/2PnxwEN0evba2NuOe80mxeIxQLOSEc6SFvdG9GWHd7SPSNt0cbmbb3m0d2vSGx3gIeoOpcC4vLOfRTz+aozXQPYWx9JrfY/jY4CI+Nrjra2O3hGNOQDeG2NTgPCeD+6Ode3jtnztpas28zaQxMKQkwPCBibAuK2REIryTW9hDSgN4Pfmza/NgYozB7/UfMLsJrbVEbbRjoMfCtMY7CfouQn/DRxuoOqqq30JUMnk9Xoo9xc7PKgtz27e1ti3o24V3+iP9C8DeSNu0z9N/Eakwlj5RWOBl7JASxg4p6bJNUyjSLqxDbE5Mr9raRO2q7bREMneN+jyGygFBhie2rJ3QbtvKHl5WSEVJgT44DwHGGPzGj9/j36/fx9c21FIzviZ3A5MDhjEmtZV7oFMYi2tKg35Kg36OqizttN5aS2NLJLUbfFNaWG9qaOGdDQ288G4odZONpAKvh2GJkE7uAh9cEqC82M/AogLKiwooLy5gUHEBxQVeBbeIuE5hLAcsYwwDiwoYWFTAMSMGdNomHrfs3BNO7RJPhXVi+o0Pd7Fld4hYvPNji36vYVAynIsKGFTs72FeAS4iuacwloOax2MYUhpgSGmAiV1cjyQet+wORdi1J0z93jD1eyLs2humfk+Y+r0R6veEU/OrtjQ5ZXvD2C7ODSrwelIhnQrqYj/liS8Oya1uZ95PeXEBRQpwEemGwljynsfTtoWdrVjcsrvFCeX6vWF27YkkwjvcIchXbtlN/Z4wDS2RrgPc58kI52RYDyryO9PJLe/E1nh5cQG2q85EJO8ojEU64fUYBiVCM1vJAO90qztRtmuPE/ArN/cc4F4DpX9/kZKAzzm+HvBREvQl5p3p0oAvVZ+aDybmE+0CPo+2ykUOcApjkRzJCPAhPbcHJ8Abk1vge8Ls2hOmYa8T6O+u+ifllSNoDkVpao3SHIqyrSnE2u1RmlujNIWitEZ7vtKY32soSQW5n9K00E4FfWI6M+gTAZ+oU6iL9B2FsYiLvB5DeWI3dfsAr7UbqKmZ0O3y4Wic5kRQN7VGaAo5082tToA3hSKp+eZQlN2hKM2tEbY2hfjndifQm1qjhHsR6smt7pKgjwHJEE8EfVGBl0K/l2CBl6DPQ2GBl6DP6zz7PQT9XoJ+p01hYjrg8+DRb8flEKcwFjmIFfg8lPsSYb4fWqOxthDPeI6ktswzgj4UTf1OPPVlIBTt8DOzbAU6BLcT3oVp4R1oN19Y4O1kuc4DP7m8tu7lQKUwFhECPi+BEi+DSwL71U80FicUjdMSjhGKJB9xWiIxWiLpZTFawjFaIvHMsrT2ybLdoYhTFo7RGk0uF6OLX6t1yxhSwZ0M6GiohYoV/0iFeNDvIejzEkhstafK/M7Wfnq7gN/5IpCsD7SrD/q82uqXrCiMRSRnfF4PJV4PJYG+/Wix1hKJWVoiMVoTIZ4K8nCMUDRGKPHcEo53/CKQ1nbjlhBFBb6M4E9+iWiNOH1EYvt+ZnuB10PA78kI6FSY+zoP9Q7t0nbpJ5/9Xg9+r8l49iWmC9Km/R4dBjgYZPU/xhhzNvBLnMuSP2Ct/XG7+gAwF5gC7ARmWWvX5XaoIiIOYwwFPkOBzwOF+3etbOcGBid02yYWt6kgb422hXUomihLBng0lhHm6e1bM+qc6T3hKDv3JEI/ve9ovMsL1ewLr8ekgtnv8+DzOOFdkDbdFuwefKlAbyvzt5v2JaYL0qbbt/F7E/37PKzYESO4dic+j9PeeTbOs8eTGKOnrSzZxmPwekzeH17oMYyNMV7gHuBMoA540xjzjLV2RVqzK4F6a+0RxpgvAD8BZvXFgEVE+pvXYygO+Cju4y3+dJFY+1Bvmw5H40Tilkg0TjQeJxzLnI7G4kRicSIxm3iOE41ZwonnSCyeMd2+XUskRjQeJxK1ROKJvqLW6T8aJxpvW65XFr+2z+ujLbw9nYS4yQhzr8eD39NWlt7G503WeTKW87b7cuD3GgoLfFz5L2P2ecy9en9ZtJkGrLHWrgUwxswDzgfSw/h84PbE9JPAfxljjNVVC0RE9klyC7M06PZIuubcVrPzQM8M+zhvLF5K1aRJRGOWWGKZWNwSiTtfHqJxm6hz+nLqnD6iiTbOcok2cUss1tamfZ/JfloiscSXk7Y+Y4nXisbbxti2nE3tlSgr9B9QYTwS2JA2Xwe036eTamOtjRpjGoHBwI5cDFJERA48zm01TVb3IW9c62X6xyv6YVT7Lx63xKzN6aGCnvTrCVzGmGuAaxKzzcaYVTnsvgKFf3/Ruu4fWs/9Q+u5f2g9w+FdVWQTxhuBw9LmRyXKOmtTZ4zxAWU4J3JlsNbOAeZk8Zq9ZoxZbK2d2hd9Syat6/6h9dw/tJ77h9Zz93retwBvAkcaY8YYYwqALwDPtGvzDPClxPQFwEs6XiwiIpKdHreME8eAbwBewPlp04PW2veMMT8AFltrnwF+BzxijFkD7MIJbBEREclCVseMrbXPAc+1K/te2nQImJnbofVan+z+lk5pXfcPref+ofXcP7Seu2G0N1lERMRd2RwzFhERkT6UF2FsjDnbGLPKGLPGGHOL2+PJR8aYw4wxC4wxK4wx7xljvub2mPKZMcZrjHnLGPOs22PJV8aYgcaYJ40x7xtjVhpjTnJ7TPnKGPONxOfGu8aYPxhjDuBLmbjjoA/jtMt1fgo4BrjIGHOMu6PKS1Hgm9baY4ATgeu1nvvU14CVbg8iz/0SeN5aOw6YhNZ3nzDGjAS+Cky11k7AORFYJ/m2c9CHMWmX67TWhoHk5Tolh6y1m621SxPTTTgfXCPdHVV+MsaMAv4f8IDbY8lXxpgy4FScX4JgrQ1baxvcHVVe8wGFietQFAGbXB7PAScfwrizy3UqJPqQMWY0UA287u5I8tYvgJuBuNsDyWNjgO3AQ4nDAQ8YY4rdHlQ+stZuBH4GrAc2A43W2hfdHdWBJx/CWPqRMaYEeAr4urV2t9vjyTfGmHOAbdbaJW6PJc/5gMnAvdbaamAPoPNN+oAxZhDO3soxwAig2BjzRXdHdeDJhzDO5nKdkgPGGD9OED9qrf2T2+PJUycD5xlj1uEccjndGPN7d4eUl+qAOmttcu/OkzjhLLn3CeBDa+12a20E+BMw3eUxHXDyIYyzuVyn7Cfj3Nn7d8BKa+3P3R5PvrLWfttaO8paOxrnb/kla622InLMWrsF2GCMOTpRdAaZt4WV3FkPnGiMKUp8jpyBTpbroF/v2tQXurpcp8vDykcnA5cCy40xbyfKbk1cnU3kYHQj8GjiS/xaYLbL48lL1trXjTFPAktxfpXxFroaVwe6ApeIiIjL8mE3tYiIyEFNYSwiIuIyhbGIiIjLFMYiIiIuUxiLiIi4TGEsIiLiMoWxiIiIyxTGIiIiLvv/gV4Vh0+LpmMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the learning curves \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scBKP4IImsGG",
    "outputId": "393c43e9-0cc9-472a-d796-e41d942fb0f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                2510      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520,260\n",
      "Trainable params: 520,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YOPUagX5EB_",
    "outputId": "7c6099e3-567a-4806-a0fb-114e862adfef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb  3 21:01:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P0    33W / 250W |   6929MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# show the GPU type used in the above computation\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARGIkiQU5PKf"
   },
   "source": [
    "### **Example 6.2:**\n",
    "\n",
    "*Use Tensorflow to implement the convolutional neural networks as structrued on page 200, and evaluate its performance using the MNIST data set and compare it with the fully-connected neural networks in the previous example.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_s_PyJkT_5cX",
    "outputId": "f555d28c-490f-4164-ac87-6a2bc6948f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 27s 11ms/step - loss: 0.2328 - accuracy: 0.9291 - val_loss: 0.0840 - val_accuracy: 0.9732\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 0.0643 - val_accuracy: 0.9794\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.0340 - val_accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0388 - val_accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0348 - val_accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0351 - val_accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0334 - val_accuracy: 0.9899\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0375 - val_accuracy: 0.9894\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0311 - val_accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 5.8223e-04 - accuracy: 0.9999 - val_loss: 0.0361 - val_accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to implement a convolutional neural network on page 200\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# define the model structure using Keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', \\\n",
    "                        padding='same', input_shape=[28, 28, 1]),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=7744, activation='relu'),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile model by attaching loss/optimizer/metric components\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=3e-2),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# learning a model\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "nwoJD4uQ7e79",
    "outputId": "f55936ba-1d3b-44bb-d159-92a2891ae3dc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU9Z3/8denunsOZobhlFvAg0MuORTEVUfReAbNZgnxjPfDJGpWd2OIcY2/xHWTmGSTzfozolHjFZZoTPxFopGVCZ4IKsopEkQYBIFhgLmP7u/vjz7o6bmhZ2po3s/HYx5V9a1vfevbNTP1rqrurjLnHCIiIuIfz+8OiIiIHOkUxiIiIj5TGIuIiPhMYSwiIuIzhbGIiIjPFMYiIiI+azOMzexRM9tpZqtbmG9m9l9mttHMPjSzKenvpoiISOZqz5nx48B5rcw/Hzg+9nMj8OChd0tEROTI0WYYO+eWAntaqXIx8ISLehvoZWaD0tVBERGRTJeO94yHAFuTpktiZSIiItIOwa5cmZndSPRSNrm5uVOHDRuWtrYjkQiep8+jdYXDb1s7DMA5wDVTRqLccC2U0cayzbcHDktZFsBS+nKgLKmui4BZyvKNxw/0rfk6Fh9vq45rvn05UlgHq7dcv/m/HovNaW09zcyzphMtt3+w7Sb+e5tw5lGdO7iVtjtmw4YNu51z/Zubl44w3gYkp+rQWFkTzrn5wHyAadOmuRUrVqRh9VHFxcUUFRWlrT1pWbPb2jkI10O4FhrqIFyXNF4bnW6oa3l+s8vUQ0Ntyvy6A2WJ+XUHhsnjDbUQqfdlGzViHnjBpJ8AWKDxdOp8L8D+8kp6FvaK1fca/zQqC0R3js2Wx+t7TcsTdS2lbjPra2mdTeom9SXeNpZSJ2Uaa7pMk/nJ81qb30ydFtYf3wG/8cabnPoP/4A1FzAthk4rO/8uXcZSlrfG48TCKxzGRRxEIrhIJDoMhw8MnYvViUSH4QhEmhuGmy7bZOiaXXb9+vWMGT26+b6aJb2U5LLm6ibVS65L07bi81uue6Bec+u1UIi8GTNa/h10kJl92tK8dITxC8DNZrYAmA7sc85tT0O70hmcg7pKqKvAVe4lUraT8N5dRPbuIbJ3D+H9ZUT27yNcXk6kopJIZSXhymoiVbWEq+uI1DZwdEMDmz3DiETP3ohE27Wkf//G+4PoaPJ+xVwzZcl1LRogXmwH73lY0ngiBGLBZV4P8AqiZYFgrCyQmN84jBrvnC1ellonNWi85PrJdZLCzGtct1E4xF9X6gtO3uFEopuPMGze/gkjQsNxkdgOzsV3pLGdqotAONK4PD6eKI/WTR53kfrGbSTXCUealCfWE4ngXKxucp1w+EC5i15ZcPGz8fgZd6w8Pt1ofot1Wp5/4ETfNVsnsWxLdZL0BdYnF6TulJN/f8nlKXUseflm6lhLbSemwZoEVOMQSsx37kBwtjFMfb1+KQQOt2DwevZk9DvLumRdbYaxmf0OKAL6mVkJ8H0gBOCc+zWwCLgA2AhUAdd0VmePWM5BfRXUVkBtOdSVEynfQ2RvKZG9uwnvKyOyr4zw/v1EysujAVpRSaQqKURrGojUhgnXOiL1RrjecA1tX2o2D7xsw8v2COSE8HJyCXthAlnZQDRoomcY0R+XMjzwQ0o5SdebLGnnGp8X26mGk3basZ19kx15YgfcECuvTQmGpO2YPGyuLDkIWpl/UMs0t2wr8oHdEA32QKDRAUqj8fhBi2fRA4Xk8dTlvNiBSBvtWSAIoZT24gc1LawnmhOxv6lGQUaizJqcwcTmNzpYaS6QaDo/NchSz3xSgqzR2U/S/M2bP2HE8BGN3sZwib+r1N9f0sFC8vyUOomn4aX+ncYKXaNlkttoZv001wbR32EgekDa0pCAF/29tTYMRA8kW20jEDsgbnWYtKxn0f7F/3Y9j7eWLeOU+Fmmc0kvJeWgKWXcJW+HFuo22t7JdVprK/ltoRbqWiBAV2kzjJ1zl7Yx3wHfTFuPMpiLRHA1NURqanCfvktk09tE9pYS3r+PSHkFkYpywlXVRCqrCVfVEomFaLg2TKTeiNR7hOuiQxexNtdnQSOQE8DLCeLl9iDQO5tgXi5efg8C+Xl4+T0J9OyJV9gbr2dvAr374vXuj9f7KAK9+uL17ImXnd2kXb0lkH7ONd2B/G3pUorOPNO/Th0h1hQX019/z50u0qcPocHpe/8103TpB7i6I+ccrrb2QEjGhpHqalxtbdKwBldb03hYU02kpjYxjNRU41KH1TVEamtx1dW4urp298vLDuDlZBPoUYCXl02gRy5Z+T3w8gsIFBTg9SzE61kYDc3Cvnh9+kfHCwrw8vMJ5OdjoVAnbjlJp8ZndTQdF2lFfX09JSUl1NTU+N2VFhUWFrJu3Tq/u9ElcnJyGDp0KKEO7IMzIoxrPvqIHi+9xM4PPoiFX00Lw2goJoeuO9g/3kAALycHy83Fy87GcnPwsnOw3BwCBT2x/tl4oSBWtxuvchtexS6MmmjZwFF4w07Ehk8h0HdQ9Aw0FqBeQQFeXl708o6ISDuUlJRQUFDAiBEjmv8gWjdQXl5OQUGB393odM45SktLKSkpYeTIke1eLjPCePUaCv74J0rNmg1HLycXr0cugT598HKysZzcpGEOlpMTG2bj5eZi2dFh43kpw5aOePZ/Bh8tgvWL4JOl0U/zDu8Lo8+H0RfCMUWQ1aMrN4+IZLiamppuHcRHEjOjb9++7Nq1q0PLZUQYF37xIlb2LOCMs8/u+j9G52DXelj/52gAf/ZetLzPMTDjpmgADzs5+kEIEZFOoiDuPg7md5ERYWxZWRAKdd0fYyQMW96OnQG/CGWfRMuHTIVZd0cDuP9ovecnIkeM/Px8Kioq/O7GYSsjwrhL1FXB31+NBvCGl6CqFAJZMPJ0OPVWGHU+9NQtuUVEpOMUxq2p3A0f/SUawH9fAg3VkF0Io86FMRfAcWdDduZ/IEFEpL2cc9xxxx385S9/wcy46667mDt3Ljt27ODCCy9k//79NDQ08OCDDzJz5kyuu+46VqxYgZlx7bXXctttt/n9EnyhME5V+vfopeePFsHWZeAi0HMoTLkqGsDDT4WAvjIkItKcP/zhD6xcuZIPPviA3bt3c9JJJ3H66afz+9//nnPPPZfvfe97hMNhqqqqWLlyJdu2bWP16tUA7N271+fe+0dhHInAZ+/DRy9GQ3hX7MZ4AybA6XdEA3jgRL3/KyKHhf/z/9aw9rP9aW3zhME9+f4Xx7Wr7uuvv86ll15KIBBgwIABnHHGGSxfvpwpU6Zw8803U19fzyWXXMKJJ57IMcccw6ZNm7jlllu48MIL+cIXvpDWfh9OjswwbqiFT16LBfAiqNgRvbfw8Jkw9Zro15B6D/e7lyIiGePUU09l6dKlvPjii1x99dXcfvvtXHXVVXzwwQe8/PLL/PrXv2bhwoU8+uijfnfVF0dOGFfvhY9fiQbwx4uhrhxCeXDcLBhzERx/DvTo43cvRUQOSXvPYDvLaaedxkMPPcTXvvY19uzZw9KlS7n//vvZsmULY8aM4YYbbqC2tpb33nuPCy64gKysLL785S8zevRorrjiCl/77qfMDuN9JdEz349ehM2vQ6QB8o6CCV+Ofv1o5OkQyvG7lyIiGeNLX/oSb731FpMmTcLM+MlPfsLAgQP54x//yNy5cwmFQuTn5/PEE0+wbds2rrnmGiKRCAD/8R//4XPv/ZNZYewcfL76QABv/yBa3m8UzLwlGsBDpkafNiMiImkT/46xmXH//fdz//33N5p/+eWXc9NNNzVZ7r333uuS/nV3mRHGn6/huI8fgZW3wN4tgEXvenXOD6IB3O84v3soIiLSogwJ47UM2v5y9P3f078No86D/KP87pWIiEi7ZEYYj/0ib+wq4PRZ5/ndExERkQ7LjDdPQzlEAvogloiIHJ4yI4xFREQOYwpjERERnymMRUREfKYwFhGRw0ZDQ4PfXegUCmMREUmLSy65hKlTpzJu3Djmz58PwEsvvcSUKVOYOXMms2bNAqI3CLnmmmuYMGECEydO5LnnngMgPz8/0dazzz7L1VdfDcDVV1/NTTfdxPTp07njjjt45513OOWUU5g8eTIzZ87ko48+AiAcDvOv//qvjB8/nokTJ/KrX/2KV199lUsuuSTR7iuvvMKXvvSlrtgcHZIZX20SERHfPfroo/Tp04fq6mpOOukkLr74Ym644QaWLl1Kv379qK+vB+CHP/whhYWFrFq1CoCysrI22y4pKeHNN98kEAiwf/9+XnvtNYLBIIsXL+bOO+/kueeeY/78+WzevJmVK1cSDAbZs2cPvXv35hvf+Aa7du2if//+PPbYY1x77bWduh0OhsJYRCST/GUe7FiV3jYHToDzf9Rmtf/6r//i+eefB2Dr1q3Mnz+f008/nZEjR1JeXk6fPtGH8SxevJgFCxYkluvdu3ebbc+ZM4dAIADAvn37+NrXvsbHH3+MmSVCfvHixdx0000Eg9Foi6/vyiuv5KmnnuKaa67hrbfe4oknnujAi+8aCmMRETlkxcXFLF68mLfeeosePXpQVFTEiSeeyPr169vdhiU9N76mpqbRvLy8vMT4v/3bv3HmmWfy/PPPs3nzZoqKilpt95prruGLX/wiOTk5zJkzJxHW3Un365GIiBy8dpzBdoZ9+/bRu3dvevTowfr163n77bepqalh6dKlfPLJJ/Tr1489e/bQp08fzjnnHB544AF+8YtfANHL1L1792bAgAGsW7eO0aNH8/zzz1NQUNDiuoYMGQLA448/nig/55xzeOihhzjzzDMTl6n79OnD4MGDGTx4MPfeey+LFy/u9G1xMPQBLhEROWTnnXceDQ0NjB07lnnz5jFjxgz69+/P/Pnz+cd//EdmzpzJ3LlzAbjrrrsoKytj/PjxTJo0iSVLlgDwox/9iIsuuoiZM2cyaNCgFtd1xx138N3vfpfJkyc3+nT19ddfz9FHH83EiROZNGkSzzzzTGLe5ZdfzrBhwxg7dmwnbYFDY845X1Y8bdo0t2LFirS1V1xc3OalCkkPbeuuoe3cNTJhO69bt67bhkxceXl5i2e6XeHmm29m8uTJXHfddV2yvuZ+J2b2rnNuWnP1dZlaREQy2tSpU8nLy+NnP/uZ311pkcJYREQy2rvvvut3F9qk94xFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhGRLpf8hKZUmzdvZvz48V3YG/8pjEVERHymMBYRkUM2b948HnjggcT0Pffcw7333susWbOYMmUKM2bM4E9/+lOH262pqUk8+3jy5MmJW2euWbOGk08+mRNPPJGJEyfy8ccfU1lZyYUXXsikSZMYP348//M//5O219fZdNMPEZEM8uN3fsz6Pe1/UlJ7jOkzhu+c/J1W68ydO5d//ud/5pvf/CYACxcu5OWXX+bWW2+lZ8+ebN68mbPPPpvZs2c3ejpTWx544AHMjFWrVrF+/Xq+8IUvsGHDBn7961/zrW99i8svv5y6ujrC4TCLFi1i8ODBvPjii0D0gRKHC50Zi4jIIZs8eTI7d+7ks88+44MPPqB3794MHDiQO++8k4kTJzJ79my2bdvG559/3qF2X3/9da644goAxowZw/Dhw9mwYQOnnHIK9913Hz/+8Y/59NNPyc3NZcKECbzyyit85zvf4bXXXqOwsLAzXmqn0JmxiEgGaesMtjPNmTOHZ599lh07djB37lyefvppdu3axbvvvktNTQ0TJkxo8pzig3XZZZcxffp0XnzxRS644AIeeughzjrrLN577z0WLVrEXXfdxaxZs7j77rvTsr7OpjAWEZG0mDt3LjfccAO7d+/mb3/7GwsXLuSoo44iFArx17/+lU8//bTDbZ522mk8/fTTnHXWWWzYsIEtW7YwevRoNm3axDHHHMOtt97Kli1b+PDDDxkzZgx9+vThiiuuoFevXjzyyCOd8Co7h8JYRETSYty4cZSXlzNkyBAGDRrE5Zdfzhe/+EUmTJjApEmTGDNmTIfb/MY3vsHXv/51JkyYQDAY5PHHHyc7O5uFCxfy5JNPEgqFEpfDly9fzre//W08zyMUCvHggw92wqvsHApjERFJm1WrViXG+/Xrx1tvvQU0fZ5xRUVFi22MGDGC1atXA5CTk8Njjz3WpM68efOYN29eo7Jzzz2Xc88995D67xd9gEtERMRnOjMWERFfrFq1iiuvvLJRWXZ2NsuWLfOpR/5pVxib2XnAL4EA8Ihz7kcp848Gfgv0itWZ55xblOa+iohIBpkwYQIrV670uxvdQpuXqc0sADwAnA+cAFxqZiekVLsLWOicmwx8Ffi/6e6oiIhIpmrPe8YnAxudc5ucc3XAAuDilDoO6BkbLwQ+S18XRUREMlt7LlMPAbYmTZcA01Pq3AP81cxuAfKAs5tryMxuBG4EGDBgAMXFxR3sbssqKirS2p60TNu6a2g7d41M2M6FhYWUl5f73Y1WhcPhbt/HdKqpqenQ31W6PsB1KfC4c+5nZnYK8KSZjXfORZIrOefmA/MBpk2b5oqKitK0eiguLiad7UnLtK27hrZz18iE7bxu3bpGXxvqjlK/2pTpcnJymDx5crvrt+cy9TZgWNL00FhZsuuAhQDOubeAHKBfu3shIiJHlNaeZ3wkak8YLweON7ORZpZF9ANaL6TU2QLMAjCzsUTDeFc6OyoiIpJuDQ0NfncBaMdlaudcg5ndDLxM9GtLjzrn1pjZD4AVzrkXgH8BHjaz24h+mOtq55zrzI6LiEhTO+67j9p16X2EYvbYMQy8885W68ybN49hw4YlHqF4zz33EAwGWbJkCWVlZdTW1nLfffdx8cWpn/9tqqKigosvvpiysjLq6+u59957E8s98cQT/PSnP8XMmDhxIk8++SSff/45N910E5s2bQLgwQcfZPDgwVx00UWJO3n99Kc/paKignvuuYeioiJOPPFEXn/9dS699FJGjRrFvffeS11dHX379uXpp59mwIABVFRUcMstt7BixQrMjO9///vs27ePDz/8kF/84hcAPPzww6xdu5b//M//POjtC+18zzj2neFFKWV3J42vBU49pJ6IiMhhK53PM87JyeH555+nZ8+e7N69mxkzZjB79mzWrl3Lvffey5tvvkm/fv3Ys2cPALfeeitnnHEGzz//POFwmIqKCsrKylpdR11dHStWrACgrKyMt99+GzPjkUce4Sc/+Qk/+9nP+OEPf0hhYWHiFp9lZWWEQiH+/d//nfvvv59QKMRjjz3GQw89dKibT3fgEhHJJG2dwXaW5OcZ79q1K/E849tuu42lS5cCJJ5nPHDgwFbbcs5x5513snTpUjzPSyz36quvMmfOHPr1i34kqU+fPgC8+uqrPPHEEwAEAgEKCwvbDOO5c+cmxktKSpg7dy7bt2+nrq6OkSNHArB48WIWLFiQqNe7d28AzjrrLP785z8zduxY6uvrmTBhQkc2VbMUxiIikhbpep5x8nKhUIgRI0Z0+DnIwWCQSOTAF3pSl8/Ly0uM33LLLdx+++3Mnj2b4uJi7rnnnlbbvv7667nvvvsYM2YM11xzTYf61RI9KEJERNJi7ty5LFiwgGeffZY5c+awb9++xPOMly5d2u7nGScvt2TJksRyZ511Fr///e8pLS0FSFymnjVrVuJxieFwmH379jFgwAB27txJaWkptbW1/PnPf251fUOGDAHgt7/9baL8nHPO4YEHHkhMx8+2p0+fztatW3nmmWe49NJL27t5WqUwFhGRtGjuecYrVqxgwoQJ/O53v2v384yTl3viiScSy40bN47vfe97nHHGGUyaNInbb78dgF/+8pcsWbKECRMmMHXqVNauXUsoFOLuu+/m5JNP5pxzzml13ffccw9z5sxh6tSpiUvgAHfddRdlZWWMHz+eSZMmsWTJksS8r3zlK5x66qmJS9eHyvz60PO0adNc/M3zdMiEL+4fLrStu4a2c9fIhO28bt06xo4d63c3WpVpN/246KKLuO2225g1a1az85v7nZjZu865ac3V15mxiIhIO+3du5dRo0aRm5vbYhAfDH2AS0REfHE4Ps+4V69ebNiwIe3tKoxFRMQXep7xAbpMLSKSAXTTw+7jYH4XCmMRkcNcTk4OpaWlCuRuwDlHaWkpOTk5HVpOl6lFRA5zQ4cOpaSkhF27uu/zeWpqajocUIernJwchg4d2qFlFMYiIoe5UCiUuIVjd1VcXNyh5/seaXSZWkRExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZ+0KYzM7z8w+MrONZjavhTpfMbO1ZrbGzJ5JbzdFREQyV7CtCmYWAB4AzgFKgOVm9oJzbm1SneOB7wKnOufKzOyozuqwiIhIpmnPmfHJwEbn3CbnXB2wALg4pc4NwAPOuTIA59zO9HZTREQkc7UnjIcAW5OmS2JlyUYBo8zsDTN728zOS1cHRUREMl2bl6k70M7xQBEwFFhqZhOcc3uTK5nZjcCNAAMGDKC4uDhNq4eKioq0tict07buGtrOXUPbuWtoO7euPWG8DRiWND00VpasBFjmnKsHPjGzDUTDeXlyJefcfGA+wLRp01xRUdFBdrup4uJi0tmetEzbumtoO3cNbeeuoe3cuvZcpl4OHG9mI80sC/gq8EJKnT8SPSvGzPoRvWy9KY39FBERyVhthrFzrgG4GXgZWAcsdM6tMbMfmNnsWLWXgVIzWwssAb7tnCvtrE6LiIhkkna9Z+ycWwQsSim7O2ncAbfHfkRERKQDdAcuERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGftSuMzew8M/vIzDaa2bxW6n3ZzJyZTUtfF0VERDJbm2FsZgHgAeB84ATgUjM7oZl6BcC3gGXp7qSIiEgma8+Z8cnARufcJudcHbAAuLiZej8EfgzUpLF/IiIiGa89YTwE2Jo0XRIrSzCzKcAw59yLaeybiIjIESF4qA2YmQf8HLi6HXVvBG4EGDBgAMXFxYe6+oSKioq0tict07buGtrOXUPbuWtoO7euPWG8DRiWND00VhZXAIwHis0MYCDwgpnNds6tSG7IOTcfmA8wbdo0V1RUdPA9T1FcXEw625OWaVt3DW3nrqHt3DW0nVvXnsvUy4HjzWykmWUBXwVeiM90zu1zzvVzzo1wzo0A3gaaBLGIiIg0r80wds41ADcDLwPrgIXOuTVm9gMzm93ZHRQREcl07XrP2Dm3CFiUUnZ3C3WLDr1bIiIiRw7dgUtERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8ZnCWERExGcKYxEREZ8pjEVERHymMBYREfGZwlhERMRnCmMRERGfKYxFRER8lhFh3BCOsHp3g9/dEBEROSgZEcaPvbGZn66o5XfvbPG7KyIiIh2WEWF81czhTOgX4M7nV/H7FVv97o6IiEiHZEQYZwcD3DI5m1OP7ccdz33In1Zu87tLIiIi7ZYRYQyQFTAevmoa00f24faFH/Dih9v97pKIiEi7ZEwYA+RmBfjN105i8rBefGvB+7y8ZoffXRIREWlTRoUxQF52kMeuOYnxQwq5+Zn3eHX95353SUREpFXtCmMzO8/MPjKzjWY2r5n5t5vZWjP70Mz+18yGp7+r7VeQE+K3157M6IEF3PTke/xtwy4/uyMiItKqNsPYzALAA8D5wAnApWZ2Qkq194FpzrmJwLPAT9Ld0Y4qzA3x1HXTOfaofG58YgVvbtztd5dERESa1Z4z45OBjc65Tc65OmABcHFyBefcEudcVWzybWBoert5cHr1yOKp605meN8eXPfbFbzzyR6/uyQiItKEOedar2D2T8B5zrnrY9NXAtOdcze3UP+/gR3OuXubmXcjcCPAgAEDpi5YsOAQu39ARUUF+fn5zc7bV+v40TvVlNU4/nVaDsf1DqRtvUei1ra1pI+2c9fQdu4a2s5w5plnvuucm9bcvGA6V2RmVwDTgDOam++cmw/MB5g2bZorKipK27qLi4tprb0Zp9Qw96G3+OXKOp66fiqThvVK27qPNG1ta0kPbeeuoe3cNbSdW9eey9TbgGFJ00NjZY2Y2dnA94DZzrna9HQvfQb0zOGZG2bQKy/Elb9Zxupt+/zukoiICNC+MF4OHG9mI80sC/gq8EJyBTObDDxENIh3pr+b6TG4Vy7PXD+D/OwgV/5mGet37Pe7SyIiIm2HsXOuAbgZeBlYByx0zq0xsx+Y2exYtfuBfOD3ZrbSzF5ooTnfDevTg9/dOIOsoMflDy/j48/L/e6SiIgc4Rq6zQkAABK+SURBVNr1PWPn3CLn3Cjn3LHOuX+Pld3tnHshNn62c26Ac+7E2M/s1lv01/C+eTxzwww8z7jskWVs2lXhd5dEROQIlnF34GqvY/vn88z104lEHJc9vIxPSyv97pKIiByhjtgwBjh+QAFPXT+dmoYwlz28jJKyqrYXEhERSbMjOowBxg7qyVPXTae8pp5LH36b7fuq/e6SiIgcYY74MAYYP6SQJ6+bzt7Kei57eBmf76/xu0siInIEURjHTBrWi8evPYmd+2u47OG32VXe7b4qLSIiGUphnGTq8D48evVJfLa3hiseWcaeyjq/uyQiIkcAhXGK6cf05ZGvTWNzaSVXPLKMvVUKZBER6VwK42acelw/5l81jY07K7jyN++wr7re7y6JiEgGUxi34IxR/Xnwiims37Gfqx97h/IaBbKIiHQOhXErZo0dwH9fNoVVJfu49vHlVNY2+N0lERHJQArjNpw7biC//Opk3v20jOt+u5zqurDfXRIRkQyjMG6HCycO4udfOZFln+zhxidXUFOvQBYRkfRRGLfTJZOH8JMvT+S1j3fz9afepbZBgSwiIumhMO6AOdOGcd+XJrDko1188+n3qWuI+N0lERHJAArjDrps+tH84OJxLF73Od9a8D4NYQWyiIgcGoXxQbjqlBHcdeFY/rJ6B7cv/IBwxPndJREROYwF/e7A4er6046hPuz48UvrCQaMn/7TJDzP/O6WiIgchhTGh+DrRcdSH47w81c2kBXwuO9LExTIIiLSYQrjQ3TrrOOpD0f41asbCQaMH148HjMFsoiItJ/COA1uP2cUdeEID/1tE6GAx90XnaBAFhGRdlMYp4GZMe+8MdQ1RHjsjc1kBTzmnT9GgSwiIu2iME4TM+Pui06gPhzhoaWbyAp6/MsXRvvdLREROQwojNPIzPjB7PE0hB2/enUjoYDHrbOO97tbIiLSzSmM08zzjPu+NIH6sOPnr2wgFPD4etGxfndLRES6MYVxJ/A84yf/NJGGSIQfv7SeUMC4/rRj/O6WiIh0UxkRxktLlvLzHT9n0d8WMTB/IIPyBjE4bzAD8wYyOH8wBVkFXd6ngGf8bM4k6sMR7n1xHVlBj6tOGdHl/RARke4vI8LYMIIEWbV7Fa9seYWGSEOj+fmh/EQwD8obdOAnPzrsn9ufgBdIe7+CAY9ffnUy9eH3uPtPawh6HpdNPzrt6xERkcNbRoTxaUNPIzwwTFFREREXobS6lM8qP2N75XZ2VOxIjG+v2M7KnSvZX7e/0fJBCzIgbwAD8wY2CurBedHwHpg3kB6hHgfVt1DA478vm8xNT77Lnc+vIhQw5kwblo6XLSIiGSIjwjiZZx79e/Snf4/+TOo/qdk6lfWVbK/YHg3o5J+K7bz7+bvsrNpJ2DV+XnGv7F5NzqiTp/vm9G3xe8XZwQAPXjGVG55YwR3PfUgo4HHJ5CFpf+0iInJ4yrgwbo+8UB7H9T6O43of1+z8hkgDu6p2sb1yO59VfsaOyh1sr4iObynfwtvb36aqoarRMlleVvTMOhbU8fes42fYA/IGMP/KaVz7+HJuX7iSUMDjwomDuuLliohIN3dEhnFbgl4wGqr5g5jClCbznXPsr9vPjsodfFbxWZMz7De2vcGu6l1NluuX248BgwcyMJjFv/zvi7y9eyKzT5jKqN6jKMwu7IqXJiIi3ZDC+CCYGYXZhRRmFzK6T/N32aoL1/F51eeJy+HJZ9i9e31GhbeKP259jT9ujdbv4fXl6PzjGNdvNNMGj+OEfmMYXjC8Uz5YJiIi3YvCuJNkBbIYVjCMYQXNf1hrX3Ud/3fp+7z/+Vq2lP+dfeFPWVO1mXX7lvPcpggAHiH6ho5mZOHxTB5wAtOHjGd039H0zOrZlS9FREQ6mcLYJ4W5WXz33OnAdABq6sNs3FnBuh2lLN/2Eev3fMS2qr+zna18Xr2Ud3a/xENrosvmWF8G5hzDqD6jOGnQOKYPHc/RBUfrLFpE5DClMO4mckIBxg8pZPyQQuZMPQY4H4CK2gY27NjP+9u28O6ONWzc+zE7az/h7zWf8knVu/x1WwRWgLksCgPDGJp3LOP7j2H60PGcPHgcPbN1Fi0i0t0pjLu5/OwgU4b3YcrwPlzHiYnyvVV1rNleyltb17Jq5zo2l2+krPZTyupeZ3X5X1mwKVovFOlL36yRjCw8jhOPOoHTR0zkhP4j8czz6RWJiEgqhfFhqlePLE49dhCnHjsImAVEP+W9q7yWd7Z+wrJtq1lfup6Sqk3sqNrC9vp3eavU8eA6IJJFDxvKwJxjGN17FFMHjaPomEkMyNcnukVE/KAwziBmxlE9c7ho3FguGjc2Ue6cY/Oevby2eXX0UndZ7FJ31Rtsql3MX3bAve+DNfSlMDCcoXnHML7fGGYMncApw4+nR1bIt9cUcRHqwnXUhmupj9RTG66lLlx34CcSmxeubzSeqBepoz5cT8ALEPJCiZ+sQBZBL0go0LgsuU6jsqR6oUCIoAVbvMmLSDo452hwDdSH66mPxH5i44aRE8xJ/IQ8//5HJT0UxkcAM2Nk396M7HsaV3FaojwcjvDe9k94Y8tqPty5Nnqpu/5TVlW+z+oqx4It4F7LJhQZTN/QCI7peTzj+o+ibNdWytZBbhYEgw3UR+rbDMzmwrM2XJsIy0bLJNVvcA2tvDJ/NRviKaHdbLC3Ui+5zsflH7Nj/Q4AHC46dK7RdFxqebvrdaB+S8s2WsQgYAE88/DMI2ABDCPgxYYWwPM8PGLzmykPWAAza9ROoq2U8tQ6rdVtqX5tpJa9NXujf8exv8fU8eRArAvXNZ2fVCc+P3W8uXabW0dyWervoyVBCx4I50B0mBvMbTodOBDgTaYDuWQHs8kJJC0bWz43mEt2ILvbfEg0fqAS3+/E9xfx8fi+JT6evM9JPlBvVL+ZNrID2fz6nF93yWtSGB/BAgGPk4Yey0lDjwUuTpTvr63k9U9X8862NawtXc+2yr+zM/I2n+9fwlux23o/907b7RseIS+LLC+LrEAWOcFssoPR6exANqFAiLxgHtnZ0fHsQHYijOLjWYEDy2cHspvOS5ofH4+3nbxM2IWb3XG2Z6fZEGloWidWr8kOuZm2axpq2B/Z33heM+tvdse7LD2/a2nD/6SnmaAFmxxoZXlZjQ60gl40OAu8ghavviQflKWOB70gDkdNQ030JxwdVjdUJ8ZrGmqoDldT01DDnpo9iXrVDdWJ8YiLdPj1ZXlZrYZ5aoAnT28s38inaz5NHLC3J0RbCsq6SN1B9T9VYl8S22/E9xnJ+5euojCWJnpm53HBqOlcMGp6osw5x+Z9JbxTsp73V29g4NBjqKgxKqod+6thf5WjrMpRVhFhT0WEmjoDmh5FF2QH6ZufRd/8bPLyosP++Vn0zc2Oludl0y82v1duCM9Lz6Vgz7xufykvHvrxcH7zzTeZOXMmRnQbxC+LJ6ZTyuPaqhefbrF+C8tjbbcZcREiRIi4COFIGIcj7MI4Fx1GXCTxkzydXKcjdZPrNFe3tbJ4+eZNmxkzakyrARovi7+10dz8kBc6bD4Y6ZyjPlLfKJybBHpSsCeHe5Ngj03vr93f5ICgJlzTeMV7DoxmB7IbHWjHwy8+nh/KJyu7cVlqvdQD9Nbmp84LeaFu9VaTwljaxcwY2WsYI3sNY8DuEEX/UNRq/aq6BnaX17G7spbSijpKK2opraxjV3l0WFpRy6elVby3pYw9lXVEmjkpDHhGn7ws+uZl0S//QFj3zc+if3w6PzsxPzere1xCO1hBL0jQC5JLLgA9Az3pl9vP5151TMACBOIHYYfJr6O4tJiisUV+d6NLmVkimDrzVrwRF6E2XEtNQw2vvfEaZ552ZrcMwu5AYSydokdWkKP7Bjm6b9uPngxHHGVVdYnQ3h0L69KKOnZX1LK7oo7Sylq2bKmitKKWyrpws+30yAo0Cu3oGXYWffKyKcgOkpsVoEdWgB5ZwdgwECuLTmcHPe0gRNLIM4/cYC65wVx6BnpSkFXgd5e6LYWx+C7gGf3ys+mXnw20/c9aXRdmd8WBM+zSiugZ+O7yaGiXVtRRUlbFByV72VNZR7i50+5meBY9iIiHdm7oQHi3GOShA/PzsgPkhhT0ItJxCmM57ORmBRjWpwfD+rR91h2JOPZV11NR20B1fZiqujBVdQ1U1Yapqg9TXdcQKwtTHR/WN1BZmzRe18DuitpEvaq6aFuufRkPtB70B8K7cZCXbK7ns2VbyA56ZIc8soPRUM8JBVouC3oEA4fH+5YickC7wtjMzgN+SfRdoEeccz9KmZ8NPAFMBUqBuc65zentqkjHeZ7ROy+L3nnp/VSkc46a+kg02OvCaQv66roGqpKDfv2qDvct4FkimA+EdCAW3illyaGeFO7R8gA5sWGiLBggJ9S4vfh4TjBAKGC6AiByENoMYzMLAA8A5wAlwHIze8E5tzap2nVAmXPuODP7KvBjYG5ndFikOzAzcmNnsH3T3HY86P+3eCknzTiF2voINQ1hausj1DaEqW2IDmvi0/WRRFnjugfq19THlquPUFnbwJ7KSEp5vN1D/7pIwDMCnhGKDwNeo2EwYAQ9I+h5TcYb1zcCnpdoJxjwonXjy8Snk9ppdvlYu0EvefkDy2zcG6ZwSxmeGWbgxT8hHhtPDGNlFhuPzzNiQ2tc5hnQaNlomWGYR9OyWBvxZRPzdHBzRGjPmfHJwEbn3CYAM1tA9EupyWF8MXBPbPxZ4L/NzJzryIU8EYEDQZ+fZQzomdOl63bOJUI5Nehrkg8GGh0IHAj8+rAjHHHURyKEw46GiKMhEqEhPh6OxIYH5oUjjvpwhPpwhKo6l5gOR1pfPr6etOxl3n4zDY10Li/lQCAa9I3DO1aM56UcMKQcQMQPODyvheVT6yUflCS1l3yg0qRPXvJBhrG3rIanPl2OZ9EDIs+iB0Oed+BAKrUsMc+alnkWP8hqXBZvO9BMWdDz8DwINFMW9DwCHo3KQgGvy/4H2xPGQ4CtSdMlxJ/710wd51yDme0D+gK709FJEekaZkZOKEBOKAB07+9lx0Xi4R9xiYOBxqHfynjYsfKDD5gwYSIORyQSvaFYxLlYyDsiDpyLlRE9YHGORvUblcXqx8dx8TIXa7tx/WjbB8bj8yIpbcT7ldw+7kBfU9uIpPYnUe9AWzSabu61pSxP8vqiR0Hx6XhZtH4EF27c9v5aR8PeGiIuemAViTjCLvq7SC5rNC+pzA8FOUFW3XNul6yrSz/AZWY3AjfGJivM7KM0Nt8PhX9X0bbuGtrOXUPbuWscltvZ/k9amxve0oz2hPE2YFjS9NBYWXN1SswsCBQS/SBXI865+cD8dqyzw8xshXNuWme0LY1pW3cNbeeuoe3cNbSdW9ee70AsB443s5FmlgV8FXghpc4LwNdi4/8EvKr3i0VERNqnzTPj2HvANwMvE/1q06POuTVm9gNghXPuBeA3wJNmtpHo3Ue/2pmdFhERySTtes/YObcIWJRSdnfSeA0wJ71d67BOufwtzdK27hrazl1D27lraDu3wnQ1WURExF+6b56IiIjPMiKMzew8M/vIzDaa2Ty/+5OJzGyYmS0xs7VmtsbMvuV3nzKZmQXM7H0z+7PffclUZtbLzJ41s/Vmts7MTvG7T5nKzG6L7TdWm9nvzKxr72ZzGDjswzjpdp3nAycAl5rZCf72KiM1AP/inDsBmAF8U9u5U30LWOd3JzLcL4GXnHNjgEloe3cKMxsC3ApMc86NJ/pBYH3IN8VhH8Yk3a7TOVcHxG/XKWnknNvunHsvNl5OdMc1xN9eZSYzGwpcCDzid18ylZkVAqcT/SYIzrk659xef3uV0YJAbuw+FD2Az3zuT7eTCWHc3O06FRKdyMxGAJOBZf72JGP9ArgDOPSnNkhLRgK7gMdibwc8YmZ5fncqEznntgE/BbYA24F9zrm/+tur7icTwli6kJnlA88B/+yc2+93fzKNmV0E7HTOvet3XzJcEJgCPOicmwxUAvq8SScws95Er1aOBAYDeWZ2hb+96n4yIYzbc7tOSQMzCxEN4qedc3/wuz8Z6lRgtpltJvqWy1lm9pS/XcpIJUCJcy5+dedZouEs6Xc28Ilzbpdzrh74AzDT5z51O5kQxu25XaccIos+VPU3wDrn3M/97k+mcs591zk31Dk3gujf8qvOOZ1FpJlzbgew1cxGx4pm0fixsJI+W4AZZtYjth+ZhT4s10SXPrWpM7R0u06fu5WJTgWuBFaZ2cpY2Z2xu7OJHI5uAZ6OHcRvAq7xuT8ZyTm3zMyeBd4j+q2M99HduJrQHbhERER8lgmXqUVERA5rCmMRERGfKYxFRER8pjAWERHxmcJYRETEZwpjERERnymMRUREfKYwFhER8dn/B9XUTZ0kX0/8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the learning curves \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRlETxfd6er4"
   },
   "source": [
    "From the above results, we can see that this simple CNN yields better performance than FCNNs as its best classification accuracy on the test set is 99.13%. \n",
    "\n",
    "In the above implementation, *padding='same'* indciates that proper zero-paddings are added prior to convolution so that the generated outputs have the same dimensions as its inputs. This is clear from the following model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElTgOFXKA2In",
    "outputId": "dedf5a83-0136-47f4-abb5-9fccf3f3c85c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_49 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 7744)              97148480  \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               991360    \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,196,874\n",
      "Trainable params: 98,196,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipKRX6aR8K1w"
   },
   "source": [
    "### **Example 6.3:**\n",
    "\n",
    "*Use Tensorflow to implement a deeper convolutional neural networks as in Figure 8.23 on page 169, and evaluate its performance using the MNIST data set.*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ax4u1oOcC-F3",
    "outputId": "c05ad764-4230-448b-dea5-0cf24285c18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3161 - accuracy: 0.8964 - val_loss: 0.0521 - val_accuracy: 0.9831\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9874\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0223 - val_accuracy: 0.9927\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0258 - val_accuracy: 0.9915\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0279 - val_accuracy: 0.9918\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0378 - val_accuracy: 0.9896\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0273 - val_accuracy: 0.9923\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0313 - val_accuracy: 0.9909\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0273 - val_accuracy: 0.9919\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0323 - val_accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to implement a convolutional neural networks in Figure 8.23 on page 169\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# define the model structure using Keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', \\\n",
    "                        padding='same', input_shape=[28, 28, 1]),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=4096, activation='relu'),\n",
    "    keras.layers.Dense(units=4096, activation='relu'),\n",
    "    keras.layers.Dense(units=1000, activation='relu'),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile model by attaching with loss/optimizer/metric\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=5e-2),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# learning a model\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-KDlPfwHBFu",
    "outputId": "aaa80705-6634-4a9a-f51e-53f5232669f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4096)              9441280   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,063,938\n",
      "Trainable params: 32,063,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf7nj49_EQVp"
   },
   "source": [
    "## **II. Using Pytorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWXy0JQqXczs"
   },
   "source": [
    "In general, *Pytorch* follows a similar pipeline of model construction as *Tensorflow*. Refer to an online [Tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) for more details. In the following examples, we use a keras-style package for Pytorch, namely *torchkeras*. As a result, we can similarly follow the above three steps in building CNNs using *Pytorch*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL79NY6GPLrj"
   },
   "source": [
    "### **Example 6.4:**\n",
    "\n",
    "*Use Pytorch to implement the convolutional neural networks as Example 6.2, and evaluate its performance using the MNIST data set.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmnVduqJCFjg"
   },
   "outputs": [],
   "source": [
    "# install keras packages for pytorch\n",
    "\n",
    "!pip install -U torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vGj7hjE_Bkx",
    "outputId": "701fb5c9-faa5-4645-baa7-1fd83d40d841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "# Convert training/test data from numpy arrays to pytorch tensors/datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    " \n",
    "X_train_ts = torch.Tensor(X_train.reshape(-1,1,28,28))\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_ts, torch.Tensor(y_train).long())\n",
    "X_test_ts = torch.Tensor(X_test.reshape(-1,1,28,28))\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_ts, torch.Tensor(y_test).long())\n",
    "\n",
    "dl_train =  torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "dl_valid =  torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(len(dl_train))\n",
    "print(len(dl_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "g69yCuPjEZ5p"
   },
   "outputs": [],
   "source": [
    "# use pyorch to implement a convolutional neural networks on page 200\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "# define CNN structure and its forward pass layer-by-layer \n",
    "class CnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3),\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 3),\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size = 3),\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7744,7744),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(7744,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "            ]\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATTqwPFND7kX",
    "outputId": "f5f0b40a-9e1d-434b-bf07-428a631c9724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
      "            Conv2d-3           [-1, 64, 22, 22]          36,928\n",
      "         MaxPool2d-4           [-1, 64, 11, 11]               0\n",
      "           Flatten-5                 [-1, 7744]               0\n",
      "            Linear-6                 [-1, 7744]      59,977,280\n",
      "              ReLU-7                 [-1, 7744]               0\n",
      "            Linear-8                  [-1, 128]         991,360\n",
      "              ReLU-9                  [-1, 128]               0\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 61,025,674\n",
      "Trainable params: 61,025,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.002991\n",
      "Forward/backward pass size (MB): 0.920975\n",
      "Params size (MB): 232.794472\n",
      "Estimated Total Size (MB): 233.718437\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# running CNNs on CPUs (by default)\n",
    "import torchkeras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true.numpy(),y_pred_cls.numpy())\n",
    "\n",
    "model = torchkeras.Model(CnnModel())\n",
    "model.summary(input_shape=(1,28,28))\n",
    "\n",
    "# compile the model by attaching various dynamic components \n",
    "model.compile(loss_func = nn.CrossEntropyLoss(),\n",
    "             optimizer= torch.optim.SGD(model.parameters(), lr=0.1),\n",
    "             metrics_dict={\"accuracy\":accuracy})\n",
    "\n",
    "# train CNNs by fitting to the training data \n",
    "dfhistory = model.fit(10,dl_train = dl_train, dl_val=dl_valid, log_step_freq=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9uzig9sOJW6",
    "outputId": "0507ffe2-a8f9-4c1b-e011-918a8e357fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
      "            Conv2d-3           [-1, 64, 22, 22]          36,928\n",
      "         MaxPool2d-4           [-1, 64, 11, 11]               0\n",
      "           Flatten-5                 [-1, 7744]               0\n",
      "            Linear-6                 [-1, 7744]      59,977,280\n",
      "              ReLU-7                 [-1, 7744]               0\n",
      "            Linear-8                  [-1, 128]         991,360\n",
      "              ReLU-9                  [-1, 128]               0\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 61,025,674\n",
      "Trainable params: 61,025,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.002991\n",
      "Forward/backward pass size (MB): 0.920975\n",
      "Params size (MB): 232.794472\n",
      "Estimated Total Size (MB): 233.718437\n",
      "----------------------------------------------------------------\n",
      "Start Training ...\n",
      "\n",
      "================================================================================2022-02-03 20:56:25\n",
      "{'step': 900, 'loss': 0.287, 'accuracy': 0.908}\n",
      "{'step': 1800, 'loss': 0.193, 'accuracy': 0.939}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   1   | 0.188 |  0.941   |   0.06   |    0.981     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:56:42\n",
      "{'step': 900, 'loss': 0.053, 'accuracy': 0.983}\n",
      "{'step': 1800, 'loss': 0.052, 'accuracy': 0.983}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   2   | 0.052 |  0.984   |  0.054   |    0.985     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:57:00\n",
      "{'step': 900, 'loss': 0.026, 'accuracy': 0.992}\n",
      "{'step': 1800, 'loss': 0.028, 'accuracy': 0.991}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   3   | 0.029 |  0.991   |  0.052   |    0.985     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:57:17\n",
      "{'step': 900, 'loss': 0.016, 'accuracy': 0.995}\n",
      "{'step': 1800, 'loss': 0.017, 'accuracy': 0.994}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   4   | 0.017 |  0.994   |  0.044   |    0.987     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:57:34\n",
      "{'step': 900, 'loss': 0.01, 'accuracy': 0.997}\n",
      "{'step': 1800, 'loss': 0.011, 'accuracy': 0.997}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   5   | 0.011 |  0.997   |  0.048   |    0.988     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:57:52\n",
      "{'step': 900, 'loss': 0.007, 'accuracy': 0.998}\n",
      "{'step': 1800, 'loss': 0.009, 'accuracy': 0.997}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   6   | 0.009 |  0.997   |  0.046   |    0.989     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:58:09\n",
      "{'step': 900, 'loss': 0.003, 'accuracy': 0.999}\n",
      "{'step': 1800, 'loss': 0.005, 'accuracy': 0.998}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   7   | 0.005 |  0.998   |  0.052   |    0.988     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:58:27\n",
      "{'step': 900, 'loss': 0.004, 'accuracy': 0.999}\n",
      "{'step': 1800, 'loss': 0.004, 'accuracy': 0.999}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   8   | 0.003 |  0.999   |  0.052   |    0.989     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:58:44\n",
      "{'step': 900, 'loss': 0.001, 'accuracy': 1.0}\n",
      "{'step': 1800, 'loss': 0.001, 'accuracy': 1.0}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   9   | 0.001 |   1.0    |  0.054   |     0.99     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:59:02\n",
      "{'step': 900, 'loss': 0.0, 'accuracy': 1.0}\n",
      "{'step': 1800, 'loss': 0.0, 'accuracy': 1.0}\n",
      "\n",
      " +-------+------+----------+----------+--------------+\n",
      "| epoch | loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+------+----------+----------+--------------+\n",
      "|   10  | 0.0  |   1.0    |  0.051   |    0.991     |\n",
      "+-------+------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:59:19\n",
      "Finished Training...\n"
     ]
    }
   ],
   "source": [
    "# Explicitly specify device and running CNNs on GPUs\n",
    "import torchkeras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = torchkeras.Model(CnnModel())\n",
    "model.summary(input_shape=(1,28,28))\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true.cpu().numpy(),y_pred_cls.cpu().numpy())\n",
    "    # .cpu() transfer the data from GPUs back to CPUs \n",
    "\n",
    "# compile the model by attaching various dynamic components \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # using GPU if available \n",
    "model.compile(loss_func = nn.CrossEntropyLoss(),\n",
    "             optimizer= torch.optim.SGD(model.parameters(), lr=0.1),\n",
    "             metrics_dict={\"accuracy\":accuracy},device = device)\n",
    "              # explicitly specify GPUs as device \n",
    "\n",
    "# train CNNs by fitting to the training data \n",
    "dfhistory = model.fit(10,dl_train = dl_train, dl_val=dl_valid, log_step_freq=900) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI8I3612RJlp"
   },
   "source": [
    "## **Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqLaZ_bCRKrA"
   },
   "source": [
    "### **Problem 6.1:**\n",
    "\n",
    "Use *Tensorflow* or *Pytorch* to implement a CNN model as in Figure 8.23 on page 169 and evaluate it on [the CIFAR10 data set](https://www.cs.toronto.edu/~kriz/cifar.html). Vary the structures in this CNN model slightly to see whether you can further improve the performance on the CIFAR10 test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKv2ciyMRPuq"
   },
   "source": [
    "### **Problem 6.2:**\n",
    "\n",
    "Use *JAX* and its automatic differenttiation to implement CNNs from scratch. Use your implementation to build the same CNN model as in Example 6.2 and evaluate it on the MNIST data set. Compare your *JAX* implementation with *TensorFlow* or *Pytorch* in terms of classification accuracy and running speed. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Lab6_Convolutional_Neural_Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
