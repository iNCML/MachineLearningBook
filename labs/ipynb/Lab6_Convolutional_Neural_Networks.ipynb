{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zl32IlrI2_2x"
   },
   "source": [
    "# **Lab 6: Convolutional Neural Networks**\n",
    "\n",
    "---\n",
    "NOTE: This is a lab project accompanying the following book [MLF] and it should be used together with the book.\n",
    "\n",
    "[MLF] *H. Jiang*, \"[Machine Learning Fundamentals: A Concise Introduction](http://wiki.eecs.yorku.ca/user/hj/research:mlfbook)\", Cambridge University Press, 2021.  ([bibtex](http://www.cse.yorku.ca/~hj/mlf-jiang.bib))\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sOfUN063FUN"
   },
   "source": [
    "The purpose of this lab is to explore more complex structures in neural networks beyond simple fully-connected networks. In particular, we focus on deep convolutional nerual networks (CNNs) for image classification as CNNs have become the dominant model for many computer vision tasks. Instead of implementing CNNs from scratch as what has been done in the previous Labs, we introduce some popular deep learning toolkits, such as *Tensorflow* and *Pytorch*, and use some examples to show how to use these toolkits to conveniently build various CNN structures and efficiently train/evaluate them with available training/test data. \n",
    "\n",
    "Prerequisites: N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFc-RfgojHyT"
   },
   "source": [
    "The most important feature in these popular deep learning toolkits (either *Tensorflow* or *Pytorch*) is to provide some flexible ways for us to specify various networks structures. These toolkits usually come up with many different syntaxes from various levels for this purpose. Some low-level syntaxes allow us to conveniently customize neural networks  in any way we prefer while other high-level syntaxes offer legible and flexible interfaces to configure  popular network structures in the literature. These toolkits allow us to directly use many popular building blocks introduced in [MLF] without reinventing the wheel, such as full connection, convolution, activation, softmax, attension, feedback and normalization layers. On the other hand, it also provides nice interfaces for us to implement any new modules. \n",
    "\n",
    "Another advantage to use these toolkits is that they come up with automatic differentiation (AD) module so that we do not need to explicitly implement error back-propagation. The learning process is almost totally automatic as long as we specify some key ingredients, such as a loss function, an optimization algorithm and relevant hyperparameters. Finally, these toolkits also provide a full support to allow us to flexibly switch hardware devices between CPUs, GPUs and even TPUs for the training/testing processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhRvb_hWnuWH"
   },
   "source": [
    "In this Lab, we only introduce how to use the high-level *Keras* style syntax to build deep convolutional neural networks for image classification tasks. When we use the *Keras* interface to build any complex neural networks, it usually consists of the following three steps:\n",
    "\n",
    "1.   **Define**: we use some highly legible syntax to clearly define the structure of neural networks in a layer by layer manner. In this step, we need to specify all network details in a static structure. \n",
    "\n",
    "2.   **Compile**: we compile the previously defined static network by associating it with some dynamic components, such as a loss function, an optimizer along with its hyperparameters, a hardware device to be used (CPUs or GPUs), an evaluation matric, etc. \n",
    "\n",
    "3.   **Fit**: we fit the compiled model to the available training data (as well as the corresponding target labels). It will run the specified optimizer and use the automatically derived gradients from AD to learn the model on the specified hardware device. \n",
    "\n",
    "In the following, we will use several examples to show how to do these three steps for convolutional neural networks using *Tensorflow* and *Pytorch*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZvsodzJlAlu"
   },
   "source": [
    "## **I. Using TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvIdky2Gi20Z"
   },
   "source": [
    "### **Example 6.1:**\n",
    "\n",
    "*Use Tensorflow to re-implement the fully-connected neural networks and compare it with various implementations in last Lab in terms of classification accuracy and running speed.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-mOvaJI1lt3"
   },
   "source": [
    "Here we can use an integer (between 0 and 9) as the target label for each image. For this case, we need to specify the CE loss function as \"*sparse_categorical_crossentropy*\" in *Tensorflow*. If we use the one-hot vector as the target label for each image, we need to specify the CE loss function as \"*categorical_crossentropy*\" in *Tensorflow*. Note that *Tensorflow* uses GPUs by default as long as  GPUs are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJKOHJdO3mwM",
    "outputId": "90e3bcb5-0023-4073-b80a-2128e2c9f30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1Jf2XqGR7y1fzOZNKLJiom7GmZZUzXhfs t10k-images-idx3-ubyte\n",
      "Processing file 1qiYu9dW3ZNrlvTFO5fI4qf8Wtr8K-pCu t10k-labels-idx1-ubyte\n",
      "Processing file 1SnWvBcUETRJ53rEJozFUUo-hOQFPKxjp train-images-idx3-ubyte\n",
      "Processing file 1kKEIi_pwVHmabByAnwZQsaMgro9XiBFE train-labels-idx1-ubyte\n",
      "Building directory structure completed\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting python_mnist\n",
      "  Downloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: python_mnist\n",
      "Successfully installed python_mnist-0.7\n"
     ]
    }
   ],
   "source": [
    "# download MNIST data from Google drive\n",
    "\n",
    "!gdown --folder https://drive.google.com/drive/folders/1r20aRjc2iu9O3kN3Xj9jNYY2uMgcERY1 2> /dev/null\n",
    "\n",
    "# install python_mnist\n",
    "\n",
    "!pip install python_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdG2Cre33vER",
    "outputId": "093c4ebc-2e63-4ace-b62d-2e5e7028a2ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,) (60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#load MINST images\n",
    "\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "\n",
    "mnist_loader = MNIST('MNIST')\n",
    "train_data, train_label = mnist_loader.load_training()\n",
    "test_data, test_label = mnist_loader.load_testing()\n",
    "X_train = np.array(train_data, dtype='float')/255.0 # norm to [0,1]\n",
    "y_train = np.array(train_label, dtype='short')\n",
    "X_test = np.array(test_data, dtype='float')/255.0 # norm to [0,1]\n",
    "y_test = np.array(test_label, dtype='short')\n",
    "\n",
    "#reshape each input vector (784) into a 28*28*1 image \n",
    "X_train = np.reshape(X_train, (-1,28,28,1)) \n",
    "X_test = np.reshape(X_test, (-1,28,28,1))\n",
    "\n",
    "# convert MNIST labels into 10-D one-hot vectors \n",
    "Y_train = np.zeros((y_train.size, y_train.max()+1))\n",
    "Y_train[np.arange(y_train.size),y_train] = 1\n",
    "Y_test = np.zeros((y_test.size, y_test.max()+1))\n",
    "Y_test[np.arange(y_test.size),y_test] = 1\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5fAyLUAeXTr",
    "outputId": "bdf36806-bd23-41ba-99b1-cef013e8f9b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.2488 - accuracy: 0.9258 - val_loss: 0.1248 - val_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0993 - accuracy: 0.9699 - val_loss: 0.1090 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0649 - accuracy: 0.9807 - val_loss: 0.0696 - val_accuracy: 0.9780\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.0682 - val_accuracy: 0.9788\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.9781\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.0640 - val_accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0590 - val_accuracy: 0.9813\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.0682 - val_accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0656 - val_accuracy: 0.9809\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.0584 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to implement a fully-connected neural networks (same structure as Lab5)\n",
    "#\n",
    "# use integers as target labels and specify CE loss as \"sparse_categorical_crossentropy\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# define the model structure using Keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dense(250, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# compile model by attaching with loss/optimizer/metric\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",      # CE loss for integer label \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-1),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# fit to training data to learn the model\n",
    "history = model.fit(X_train, y_train, epochs=10,          # y_train: integer labels\n",
    "                    validation_data=(X_test, y_test))     # y_test: integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCeB1Lsw3Rf6",
    "outputId": "b94d6bd7-2530-455a-9dd6-b0bbf499a597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2488 - accuracy: 0.9258 - val_loss: 0.1248 - val_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0993 - accuracy: 0.9699 - val_loss: 0.1090 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0649 - accuracy: 0.9807 - val_loss: 0.0696 - val_accuracy: 0.9780\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.0682 - val_accuracy: 0.9788\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.9781\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.0640 - val_accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0590 - val_accuracy: 0.9813\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.0682 - val_accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0656 - val_accuracy: 0.9809\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.0584 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to implement a fully-connected neural networks\n",
    "# use one-hot target labels and specify CE loss as \"categorical_crossentropy\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# define the model structure using Keras  (same network structure as Lab5)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dense(250, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# compile model by attaching with loss/optimizer/metric\n",
    "model.compile(loss=\"categorical_crossentropy\",      # CE loss for one-hot vector label \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-1),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# fit to training data to learn the model  \n",
    "history = model.fit(X_train, Y_train, epochs=10,        # Y_train: one-hot vector labels  \n",
    "                    validation_data=(X_test, Y_test))   # Y_test: one-hot vector labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "YNxIUHWAmEAP",
    "outputId": "81807ed2-a862-49d2-e7b9-e02293f3c008"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the learning curves \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scBKP4IImsGG",
    "outputId": "393c43e9-0cc9-472a-d796-e41d942fb0f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                2510      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520,260\n",
      "Trainable params: 520,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YOPUagX5EB_",
    "outputId": "7c6099e3-567a-4806-a0fb-114e862adfef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb  3 21:01:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P0    33W / 250W |   6929MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# show the GPU type used in the above computation\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARGIkiQU5PKf"
   },
   "source": [
    "### **Example 6.2:**\n",
    "\n",
    "*Use Tensorflow to implement the convolutional neural networks as structrued on page 200, and evaluate its performance using the MNIST data set and compare it with the fully-connected neural networks in the previous example.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_s_PyJkT_5cX",
    "outputId": "f555d28c-490f-4164-ac87-6a2bc6948f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 27s 11ms/step - loss: 0.2328 - accuracy: 0.9291 - val_loss: 0.0840 - val_accuracy: 0.9732\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 0.0643 - val_accuracy: 0.9794\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.0340 - val_accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0388 - val_accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0348 - val_accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0351 - val_accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0334 - val_accuracy: 0.9899\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0375 - val_accuracy: 0.9894\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0311 - val_accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 5.8223e-04 - accuracy: 0.9999 - val_loss: 0.0361 - val_accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to implement a convolutional neural network on page 200\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# define the model structure using Keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', \\\n",
    "                        padding='same', input_shape=[28, 28, 1]),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=7744, activation='relu'),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile model by attaching loss/optimizer/metric components\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=3e-2),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# learning a model\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "nwoJD4uQ7e79",
    "outputId": "f55936ba-1d3b-44bb-d159-92a2891ae3dc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the learning curves \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRlETxfd6er4"
   },
   "source": [
    "From the above results, we can see that this simple CNN yields better performance than FCNNs as its best classification accuracy on the test set is 99.13%. \n",
    "\n",
    "In the above implementation, *padding='same'* indciates that proper zero-paddings are added prior to convolution so that the generated outputs have the same dimensions as the inputs. This is clear from the following model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElTgOFXKA2In",
    "outputId": "dedf5a83-0136-47f4-abb5-9fccf3f3c85c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_49 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 7744)              97148480  \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               991360    \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,196,874\n",
      "Trainable params: 98,196,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipKRX6aR8K1w"
   },
   "source": [
    "### **Example 6.3:**\n",
    "\n",
    "*Use Tensorflow to implement a deeper convolutional neural networks as in Figure 8.23 on page 169, and evaluate its performance using the MNIST data set.*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ax4u1oOcC-F3",
    "outputId": "c05ad764-4230-448b-dea5-0cf24285c18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3161 - accuracy: 0.8964 - val_loss: 0.0521 - val_accuracy: 0.9831\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9874\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0223 - val_accuracy: 0.9927\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0258 - val_accuracy: 0.9915\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0279 - val_accuracy: 0.9918\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0378 - val_accuracy: 0.9896\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0273 - val_accuracy: 0.9923\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0313 - val_accuracy: 0.9909\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0273 - val_accuracy: 0.9919\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0323 - val_accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to implement a convolutional neural networks in Figure 8.23 on page 169\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# define the model structure using Keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', \\\n",
    "                        padding='same', input_shape=[28, 28, 1]),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=4096, activation='relu'),\n",
    "    keras.layers.Dense(units=4096, activation='relu'),\n",
    "    keras.layers.Dense(units=1000, activation='relu'),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile model by attaching with loss/optimizer/metric\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=5e-2),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# learning a model\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-KDlPfwHBFu",
    "outputId": "aaa80705-6634-4a9a-f51e-53f5232669f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4096)              9441280   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,063,938\n",
      "Trainable params: 32,063,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf7nj49_EQVp"
   },
   "source": [
    "## **II. Using Pytorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWXy0JQqXczs"
   },
   "source": [
    "In general, *Pytorch* follows a similar pipeline of model construction as *Tensorflow*. Refer to an online [Tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) for more details. In the following examples, we use a keras-style package for Pytorch, namely *torchkeras*. As a result, we can similarly follow the above three steps in building CNNs using *Pytorch*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL79NY6GPLrj"
   },
   "source": [
    "### **Example 6.4:**\n",
    "\n",
    "*Use Pytorch to implement the convolutional neural networks as Example 6.2, and evaluate its performance using the MNIST data set.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmnVduqJCFjg"
   },
   "outputs": [],
   "source": [
    "# install keras packages for pytorch\n",
    "\n",
    "!pip install -U torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vGj7hjE_Bkx",
    "outputId": "701fb5c9-faa5-4645-baa7-1fd83d40d841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "# Convert training/test data from numpy arrays to pytorch tensors/datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    " \n",
    "X_train_ts = torch.Tensor(X_train.reshape(-1,1,28,28))\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_ts, torch.Tensor(y_train).long())\n",
    "X_test_ts = torch.Tensor(X_test.reshape(-1,1,28,28))\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_ts, torch.Tensor(y_test).long())\n",
    "\n",
    "dl_train =  torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "dl_valid =  torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(len(dl_train))\n",
    "print(len(dl_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g69yCuPjEZ5p"
   },
   "outputs": [],
   "source": [
    "# use pyorch to implement a convolutional neural networks on page 200\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "# define CNN structure and its forward pass layer-by-layer \n",
    "class CnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,out_channels=32,kernel_size = 3),\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 3),\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size = 3),\n",
    "            nn.MaxPool2d(kernel_size = 2,stride = 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7744,7744),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(7744,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "            ]\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATTqwPFND7kX",
    "outputId": "f5f0b40a-9e1d-434b-bf07-428a631c9724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
      "            Conv2d-3           [-1, 64, 22, 22]          36,928\n",
      "         MaxPool2d-4           [-1, 64, 11, 11]               0\n",
      "           Flatten-5                 [-1, 7744]               0\n",
      "            Linear-6                 [-1, 7744]      59,977,280\n",
      "              ReLU-7                 [-1, 7744]               0\n",
      "            Linear-8                  [-1, 128]         991,360\n",
      "              ReLU-9                  [-1, 128]               0\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 61,025,674\n",
      "Trainable params: 61,025,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.002991\n",
      "Forward/backward pass size (MB): 0.920975\n",
      "Params size (MB): 232.794472\n",
      "Estimated Total Size (MB): 233.718437\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# running CNNs on CPUs (by default)\n",
    "import torchkeras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true.numpy(),y_pred_cls.numpy())\n",
    "\n",
    "model = torchkeras.Model(CnnModel())\n",
    "model.summary(input_shape=(1,28,28))\n",
    "\n",
    "# compile the model by attaching various dynamic components \n",
    "model.compile(loss_func = nn.CrossEntropyLoss(),\n",
    "             optimizer= torch.optim.SGD(model.parameters(), lr=0.1),\n",
    "             metrics_dict={\"accuracy\":accuracy})\n",
    "\n",
    "# train CNNs by fitting to the training data \n",
    "dfhistory = model.fit(10,dl_train = dl_train, dl_val=dl_valid, log_step_freq=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9uzig9sOJW6",
    "outputId": "0507ffe2-a8f9-4c1b-e011-918a8e357fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
      "            Conv2d-3           [-1, 64, 22, 22]          36,928\n",
      "         MaxPool2d-4           [-1, 64, 11, 11]               0\n",
      "           Flatten-5                 [-1, 7744]               0\n",
      "            Linear-6                 [-1, 7744]      59,977,280\n",
      "              ReLU-7                 [-1, 7744]               0\n",
      "            Linear-8                  [-1, 128]         991,360\n",
      "              ReLU-9                  [-1, 128]               0\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 61,025,674\n",
      "Trainable params: 61,025,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.002991\n",
      "Forward/backward pass size (MB): 0.920975\n",
      "Params size (MB): 232.794472\n",
      "Estimated Total Size (MB): 233.718437\n",
      "----------------------------------------------------------------\n",
      "Start Training ...\n",
      "\n",
      "================================================================================2022-02-03 20:56:25\n",
      "{'step': 900, 'loss': 0.287, 'accuracy': 0.908}\n",
      "{'step': 1800, 'loss': 0.193, 'accuracy': 0.939}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   1   | 0.188 |  0.941   |   0.06   |    0.981     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:56:42\n",
      "{'step': 900, 'loss': 0.053, 'accuracy': 0.983}\n",
      "{'step': 1800, 'loss': 0.052, 'accuracy': 0.983}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   2   | 0.052 |  0.984   |  0.054   |    0.985     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:57:00\n",
      "{'step': 900, 'loss': 0.026, 'accuracy': 0.992}\n",
      "{'step': 1800, 'loss': 0.028, 'accuracy': 0.991}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   3   | 0.029 |  0.991   |  0.052   |    0.985     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:57:17\n",
      "{'step': 900, 'loss': 0.016, 'accuracy': 0.995}\n",
      "{'step': 1800, 'loss': 0.017, 'accuracy': 0.994}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   4   | 0.017 |  0.994   |  0.044   |    0.987     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:57:34\n",
      "{'step': 900, 'loss': 0.01, 'accuracy': 0.997}\n",
      "{'step': 1800, 'loss': 0.011, 'accuracy': 0.997}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   5   | 0.011 |  0.997   |  0.048   |    0.988     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:57:52\n",
      "{'step': 900, 'loss': 0.007, 'accuracy': 0.998}\n",
      "{'step': 1800, 'loss': 0.009, 'accuracy': 0.997}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   6   | 0.009 |  0.997   |  0.046   |    0.989     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:58:09\n",
      "{'step': 900, 'loss': 0.003, 'accuracy': 0.999}\n",
      "{'step': 1800, 'loss': 0.005, 'accuracy': 0.998}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   7   | 0.005 |  0.998   |  0.052   |    0.988     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:58:27\n",
      "{'step': 900, 'loss': 0.004, 'accuracy': 0.999}\n",
      "{'step': 1800, 'loss': 0.004, 'accuracy': 0.999}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   8   | 0.003 |  0.999   |  0.052   |    0.989     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:58:44\n",
      "{'step': 900, 'loss': 0.001, 'accuracy': 1.0}\n",
      "{'step': 1800, 'loss': 0.001, 'accuracy': 1.0}\n",
      "\n",
      " +-------+-------+----------+----------+--------------+\n",
      "| epoch |  loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "|   9   | 0.001 |   1.0    |  0.054   |     0.99     |\n",
      "+-------+-------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:59:02\n",
      "{'step': 900, 'loss': 0.0, 'accuracy': 1.0}\n",
      "{'step': 1800, 'loss': 0.0, 'accuracy': 1.0}\n",
      "\n",
      " +-------+------+----------+----------+--------------+\n",
      "| epoch | loss | accuracy | val_loss | val_accuracy |\n",
      "+-------+------+----------+----------+--------------+\n",
      "|   10  | 0.0  |   1.0    |  0.051   |    0.991     |\n",
      "+-------+------+----------+----------+--------------+\n",
      "\n",
      "================================================================================2022-02-03 20:59:19\n",
      "Finished Training...\n"
     ]
    }
   ],
   "source": [
    "# Explicitly specify device and running CNNs on GPUs\n",
    "import torchkeras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = torchkeras.Model(CnnModel())\n",
    "model.summary(input_shape=(1,28,28))\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    y_pred_cls = torch.argmax(nn.Softmax(dim=1)(y_pred),dim=1).data\n",
    "    return accuracy_score(y_true.cpu().numpy(),y_pred_cls.cpu().numpy())\n",
    "    # .cpu() transfer the data from GPUs back to CPUs \n",
    "\n",
    "# compile the model by attaching various dynamic components \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # using GPU if available \n",
    "model.compile(loss_func = nn.CrossEntropyLoss(),\n",
    "             optimizer= torch.optim.SGD(model.parameters(), lr=0.1),\n",
    "             metrics_dict={\"accuracy\":accuracy},device = device)\n",
    "              # explicitly specify GPUs as device \n",
    "\n",
    "# train CNNs by fitting to the training data \n",
    "dfhistory = model.fit(10,dl_train = dl_train, dl_val=dl_valid, log_step_freq=900) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI8I3612RJlp"
   },
   "source": [
    "## **Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqLaZ_bCRKrA"
   },
   "source": [
    "### **Problem 6.1:**\n",
    "\n",
    "Use *Tensorflow* or *Pytorch* to implement a CNN model as in Figure 8.23 on page 169 and evaluate it on [the CIFAR10 data set](https://www.cs.toronto.edu/~kriz/cifar.html). Vary the structures in this CNN model slightly to see whether you can further improve the performance on the CIFAR10 test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKv2ciyMRPuq"
   },
   "source": [
    "### **Problem 6.2:**\n",
    "\n",
    "Use *JAX* and its automatic differenttiation to implement CNNs from scratch. Use your implementation to build the same CNN model as in Example 6.2 and evaluate it on the MNIST data set. Compare your *JAX* implementation with *TensorFlow* or *Pytorch* in terms of classification accuracy and running speed. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
